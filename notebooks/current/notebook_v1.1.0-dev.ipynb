{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "version-metadata",
      "metadata": {},
      "source": [
        "# System Prompt Generator for AI Engineers\n",
        "## Version: 1.1.0-dev\n",
        "## Last Modified: 2025-09-05\n",
        "## Author: AI Engineer Team\n",
        "## Stage: Development\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ v1.1.0 é–‹ç™ºä¸­ã®æ–°æ©Ÿèƒ½\n",
        "- ğŸ“ **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ç®¡ç†**: ç”Ÿæˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¿å­˜ãƒ»å†åˆ©ç”¨\n",
        "- ğŸ”¢ **ãƒãƒƒãƒå‡¦ç†**: è¤‡æ•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€æ‹¬ç”Ÿæˆ\n",
        "- ğŸ“Š **å¼·åŒ–ã•ã‚ŒãŸå¯è¦–åŒ–**: å“è³ªã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ\n",
        "- ğŸ¯ **æ–°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: RAGã‚·ã‚¹ãƒ†ãƒ ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€æ¨è–¦ã‚¨ãƒ³ã‚¸ãƒ³å‘ã‘ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "- âš¡ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„**: ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "main-title",
      "metadata": {},
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  for AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢\n",
        "\n",
        "## æ¦‚è¦\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºçµŒé¨“ã®å°‘ãªã„AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒPoCé–‹ç™ºæ™‚ã«åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚\n",
        "\n",
        "### ä¸»è¦æ©Ÿèƒ½\n",
        "- **è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ**: ç”¨é€”åˆ¥ãƒ»ç›®çš„åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ\n",
        "- **LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆâ†’è©•ä¾¡â†’æ”¹å–„ã®è‡ªå‹•åŒ–\n",
        "- **å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ **: Claude APIã«ã‚ˆã‚‹åŠ¹æœæ¸¬å®š\n",
        "- **ãƒ†ã‚¹ãƒˆç’°å¢ƒ**: FastAPI + Web UIã§ã®å®Ÿè¡Œæ¤œè¨¼\n",
        "- **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†**: PoCå‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³é›†\n",
        "\n",
        "### åˆ©ç”¨å¯¾è±¡\n",
        "- AIæŠ€è¡“ã«çŸ¥è¦‹ãŒã‚ã‚‹ãŒã€ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºçµŒé¨“ãŒæµ…ã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢\n",
        "- PoCé–‹ç™ºã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒå¿…è¦ãªæ–¹\n",
        "- åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆæ‰‹æ³•ã‚’å­¦ã³ãŸã„æ–¹"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-1-environment",
      "metadata": {},
      "source": [
        "# 1. ç’°å¢ƒè¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "install-dependencies",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸ\n",
            "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«çµæœ: æˆåŠŸ\n"
          ]
        }
      ],
      "source": [
        "# ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_requirements():\n",
        "    \"\"\"requirements.txtã‹ã‚‰ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'], \n",
        "                              capture_output=True, text=True, check=True)\n",
        "        print(\"âœ… ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âŒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        print(f\"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}\")\n",
        "        return False\n",
        "\n",
        "# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Ÿè¡Œ\n",
        "install_success = install_requirements()\n",
        "print(f\"ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«çµæœ: {'æˆåŠŸ' if install_success else 'å¤±æ•—'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "load-environment",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\n",
            "\n",
            "=== ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯ ===\n",
            "âœ… ANTHROPIC_API_KEY: sk-a...zwAA\n",
            "âœ… APP_HOST: localhost\n",
            "âœ… APP_PORT: 8000\n",
            "âœ… DEFAULT_MODEL: claude-3-sonnet-20240229\n",
            "\n",
            "ğŸ‰ ç’°å¢ƒè¨­å®šå®Œäº†ï¼\n"
          ]
        }
      ],
      "source": [
        "# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# .envãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨èª­ã¿è¾¼ã¿\n",
        "env_path = Path('.env')\n",
        "if not env_path.exists():\n",
        "    print(\"âš ï¸  .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "    print(\"ğŸ’¡ .env.exampleã‚’ã‚³ãƒ”ãƒ¼ã—ã¦.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "    print(\"\\nä¾‹:\")\n",
        "    print(\"cp .env.example .env\")\n",
        "    print(\"# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦APIã‚­ãƒ¼ã‚’è¨­å®š\")\n",
        "else:\n",
        "    load_dotenv()\n",
        "    print(\"âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
        "\n",
        "# ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª\n",
        "required_vars = [\n",
        "    'ANTHROPIC_API_KEY',\n",
        "    'APP_HOST',\n",
        "    'APP_PORT',\n",
        "    'DEFAULT_MODEL'\n",
        "]\n",
        "\n",
        "print(\"\\n=== ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯ ===\")\n",
        "all_vars_set = True\n",
        "for var in required_vars:\n",
        "    value = os.getenv(var)\n",
        "    if value:\n",
        "        # APIã‚­ãƒ¼ã¯ä¸€éƒ¨ãƒã‚¹ã‚¯ã—ã¦è¡¨ç¤º\n",
        "        if 'KEY' in var and len(value) > 8:\n",
        "            display_value = f\"{value[:4]}...{value[-4:]}\"\n",
        "        else:\n",
        "            display_value = value\n",
        "        print(f\"âœ… {var}: {display_value}\")\n",
        "    else:\n",
        "        print(f\"âŒ {var}: æœªè¨­å®š\")\n",
        "        all_vars_set = False\n",
        "\n",
        "if all_vars_set:\n",
        "    print(\"\\nğŸ‰ ç’°å¢ƒè¨­å®šå®Œäº†ï¼\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸  ä¸€éƒ¨ã®ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "import-libraries",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Anthropicãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\n",
            "âš ï¸ LangChainãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯åˆ©ç”¨ä¸å¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: No module named 'langchain_community'\n",
            "âœ… LangGraphãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\n",
            "âœ… FastAPIãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\n",
            "âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\n",
            "\n",
            "ğŸš€ åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿å®Œäº†\n"
          ]
        }
      ],
      "source": [
        "# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "import asyncio\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "from dataclasses import dataclass\n",
        "import traceback\n",
        "import os\n",
        "\n",
        "# LLMé–¢é€£\n",
        "try:\n",
        "    import anthropic\n",
        "    print(\"âœ… Anthropicãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Anthropicãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "\n",
        "# LangChainé–¢é€£ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ - ã‚¨ãƒ©ãƒ¼ã‚’è¨±å®¹ï¼‰\n",
        "try:\n",
        "    from langchain_anthropic import ChatAnthropic\n",
        "    print(\"âœ… LangChain Anthropicãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "except ImportError:\n",
        "    try:\n",
        "        from langchain.llms import Anthropic\n",
        "        print(\"âœ… LangChainåŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "    except ImportError as e:\n",
        "        print(f\"âš ï¸ LangChainãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯åˆ©ç”¨ä¸å¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: {e}\")\n",
        "\n",
        "# LangGraphé–¢é€£ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ - ã‚¨ãƒ©ãƒ¼ã‚’è¨±å®¹ï¼‰\n",
        "try:\n",
        "    from langgraph.graph import StateGraph\n",
        "    from langgraph.checkpoint.memory import MemorySaver\n",
        "    print(\"âœ… LangGraphãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "except ImportError as e:\n",
        "    print(f\"âš ï¸ LangGraphãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯åˆ©ç”¨ä¸å¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: {e}\")\n",
        "\n",
        "# Webé–¢é€£\n",
        "try:\n",
        "    from fastapi import FastAPI, HTTPException\n",
        "    from fastapi.responses import HTMLResponse\n",
        "    from pydantic import BaseModel\n",
        "    import uvicorn\n",
        "    print(\"âœ… FastAPIãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ FastAPIãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    plt.style.use('default')\n",
        "    print(\"âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "\n",
        "# ãƒ­ã‚°è¨­å®š\n",
        "logging.basicConfig(\n",
        "    level=getattr(logging, os.getenv('LOG_LEVEL', 'INFO')),\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\\nğŸš€ åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿å®Œäº†\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "api-connection-test",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:12:54,747 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Claude APIæ¥ç¶šæˆåŠŸ\n",
            "ğŸ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: claude-3-5-sonnet-20241022\n",
            "ğŸ“ ãƒ¬ã‚¹ãƒãƒ³ã‚¹: API connection successful!\n",
            "\n",
            "ğŸ”— APIæ¥ç¶šãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Safe API key handling\n",
        "import os\n",
        "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"âš ï¸ ANTHROPIC_API_KEY not set. Some features may not work.\")\n",
        "    # Continue with limited functionality\n",
        "\n",
        "# APIæ¥ç¶šãƒ†ã‚¹ãƒˆ\n",
        "# Jupyterç’°å¢ƒã§asyncioå®Ÿè¡Œã‚’ã‚µãƒãƒ¼ãƒˆ\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def test_claude_api():\n",
        "    \"\"\"Claude APIã®æ¥ç¶šãƒ†ã‚¹ãƒˆ\"\"\"\n",
        "    try:\n",
        "        client = anthropic.AsyncAnthropic(\n",
        "            api_key=os.getenv('ANTHROPIC_API_KEY')\n",
        "        )\n",
        "        \n",
        "        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã«ä¿®æ­£\n",
        "        # claude-3-sonnet-20240229 â†’ claude-3-5-sonnet-20241022 ã¾ãŸã¯ claude-3-sonnet-20240229\n",
        "        model_name = \"claude-3-5-sonnet-20241022\"  # æœ€æ–°ãƒ¢ãƒ‡ãƒ«\n",
        "        \n",
        "        # ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡\n",
        "        response = await client.messages.create(\n",
        "            model=model_name,\n",
        "            max_tokens=100,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": \"Hello! Please respond with 'API connection successful!'\"}\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        print(\"âœ… Claude APIæ¥ç¶šæˆåŠŸ\")\n",
        "        print(f\"ğŸ“ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}\")\n",
        "        print(f\"ğŸ“ ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.content[0].text}\")\n",
        "        return True\n",
        "        \n",
        "    except anthropic.NotFoundError as e:\n",
        "        print(f\"âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)}\")\n",
        "        print(\"ğŸ’¡ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Claude APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# æ¥ç¶šãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
        "if os.getenv('ANTHROPIC_API_KEY') and os.getenv('ANTHROPIC_API_KEY') != 'your_claude_api_key_here':\n",
        "    # asyncio.run()ã‚’ä½¿ç”¨ã—ã¦Jupyterç’°å¢ƒã§å®Ÿè¡Œ\n",
        "    api_test_result = asyncio.run(test_claude_api())\n",
        "else:\n",
        "    print(\"âš ï¸  ANTHROPIC_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€APIãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
        "    api_test_result = False\n",
        "\n",
        "print(f\"\\nğŸ”— APIæ¥ç¶šãƒ†ã‚¹ãƒˆçµæœ: {'æˆåŠŸ' if api_test_result else 'å¤±æ•—'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-history",
      "metadata": {},
      "source": [
        "# ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (v1.1.0 æ–°æ©Ÿèƒ½)\n",
        "\n",
        "ç”Ÿæˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¿å­˜ã€æ¤œç´¢ã€å†åˆ©ç”¨æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "id": "import-history",
      "metadata": {},
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from src.prompt_history import PromptHistory\n",
        "\n",
        "# å±¥æ­´ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–\n",
        "history_manager = PromptHistory()\n",
        "\n",
        "print(\"âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ\")\n",
        "print(f\"ğŸ“Š ç¾åœ¨ã®å±¥æ­´æ•°: {len(history_manager.history)} ä»¶\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "save-prompt-demo",
      "metadata": {},
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜ã®ãƒ‡ãƒ¢\n",
        "demo_prompt_id = history_manager.save_prompt(\n",
        "    prompt_type=\"data_analysis\",\n",
        "    user_requirements=\"å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­£ç¯€æ€§ã‚’åˆ†æã—ãŸã„\",\n",
        "    generated_prompt=\"ä»¥ä¸‹ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šã—ã¦ãã ã•ã„...\",\n",
        "    quality_scores={\n",
        "        \"clarity\": 8.5,\n",
        "        \"specificity\": 7.8,\n",
        "        \"completeness\": 9.0,\n",
        "        \"efficiency\": 8.2,\n",
        "        \"reproducibility\": 8.7,\n",
        "        \"overall\": 8.4\n",
        "    },\n",
        "    metadata={\"domain\": \"eã‚³ãƒãƒ¼ã‚¹\", \"priority\": \"high\"}\n",
        ")\n",
        "\n",
        "print(f\"âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ (ID: {demo_prompt_id})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "search-history",
      "metadata": {},
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¤œç´¢ã®ãƒ‡ãƒ¢\n",
        "import pandas as pd\n",
        "\n",
        "# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢\n",
        "results = history_manager.search_prompts(keyword=\"å£²ä¸Š\")\n",
        "print(f\"ğŸ” 'å£²ä¸Š'ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {len(results)} ä»¶\\n\")\n",
        "\n",
        "# é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—\n",
        "best_prompts = history_manager.get_best_prompts(limit=3)\n",
        "print(\"â­ ãƒˆãƒƒãƒ—3ã®é«˜è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\")\n",
        "for i, prompt in enumerate(best_prompts, 1):\n",
        "    score = prompt.get('quality_scores', {}).get('overall', 0)\n",
        "    print(f\"{i}. {prompt['prompt_type']} - ã‚¹ã‚³ã‚¢: {score}\")\n",
        "\n",
        "# çµ±è¨ˆæƒ…å ±\n",
        "stats = history_manager.get_statistics()\n",
        "print(f\"\\nğŸ“Š çµ±è¨ˆæƒ…å ±:\")\n",
        "print(f\"- ç·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°: {stats['total_prompts']}\")\n",
        "print(f\"- å¹³å‡ã‚¹ã‚³ã‚¢: {stats['average_score']}\")\n",
        "print(f\"- æœ€é«˜ã‚¹ã‚³ã‚¢: {stats['best_score']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "history-visualization",
      "metadata": {},
      "source": [
        "# å±¥æ­´ã®å¯è¦–åŒ–\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ã®åˆ†å¸ƒ\n",
        "stats = history_manager.get_statistics()\n",
        "if stats['prompt_types']:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    # ã‚¿ã‚¤ãƒ—åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ\n",
        "    types = list(stats['prompt_types'].keys())\n",
        "    counts = list(stats['prompt_types'].values())\n",
        "    ax1.bar(types, counts, color='skyblue')\n",
        "    ax1.set_title('ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ä»¶æ•°')\n",
        "    ax1.set_xlabel('ã‚¿ã‚¤ãƒ—')\n",
        "    ax1.set_ylabel('ä»¶æ•°')\n",
        "    \n",
        "    # å“è³ªã‚¹ã‚³ã‚¢åˆ†å¸ƒï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰\n",
        "    scores = [p.get('quality_scores', {}).get('overall', 0) \n",
        "             for p in history_manager.history if p.get('quality_scores')]\n",
        "    if scores:\n",
        "        ax2.hist(scores, bins=10, color='lightgreen', edgecolor='black')\n",
        "        ax2.set_title('å“è³ªã‚¹ã‚³ã‚¢åˆ†å¸ƒ')\n",
        "        ax2.set_xlabel('ã‚¹ã‚³ã‚¢')\n",
        "        ax2.set_ylabel('ä»¶æ•°')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"ğŸ“Š è¡¨ç¤ºã™ã‚‹å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "export-import",
      "metadata": {},
      "source": [
        "# å±¥æ­´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ/ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "\n",
        "# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
        "export_path = history_manager.export_history(\"prompt_history_backup.json\")\n",
        "print(f\"ğŸ’¾ å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {export_path}\")\n",
        "\n",
        "# ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¾‹ï¼ˆå®Ÿéš›ã«ã¯åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰\n",
        "# imported_count = history_manager.import_history(\"other_history.json\")\n",
        "# print(f\"ğŸ“¥ {imported_count} ä»¶ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "section-2-theory",
      "metadata": {},
      "source": [
        "# 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆç†è«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prompt-design-principles",
      "metadata": {},
      "source": [
        "## 2.1 PoCå‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆåŸå‰‡\n",
        "\n",
        "### åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç‰¹å¾´\n",
        "1. **æ˜ç¢ºãªç›®çš„è¨­å®š**: ä½•ã‚’é”æˆã—ãŸã„ã‹ã‚’å…·ä½“çš„ã«è¨˜è¿°\n",
        "2. **æ–‡è„ˆã®æä¾›**: å¿…è¦ãªèƒŒæ™¯æƒ…å ±ã‚’é©åˆ‡ã«å«ã‚€\n",
        "3. **æœŸå¾…ã™ã‚‹å‡ºåŠ›ã®å®šç¾©**: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚„è©³ç´°ãƒ¬ãƒ™ãƒ«ã‚’æŒ‡å®š\n",
        "4. **åˆ¶ç´„ã®æ˜ç¤º**: é¿ã‘ã‚‹ã¹ãå†…å®¹ã‚„åˆ¶é™äº‹é …ã‚’è¨˜è¿°\n",
        "5. **ä¾‹ç¤ºã®æ´»ç”¨**: Few-shot learningã§å“è³ªå‘ä¸Š\n",
        "\n",
        "### PoCãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç‰¹æœ‰ã®è€ƒæ…®ç‚¹\n",
        "- **è¿…é€Ÿæ€§é‡è¦–**: çŸ­æœŸé–“ã§ã®çµæœå‡ºåŠ›\n",
        "- **å®Ÿé¨“æ€§å®¹èª**: è©¦è¡ŒéŒ¯èª¤ã‚’å‰æã¨ã—ãŸæŸ”è»Ÿæ€§\n",
        "- **èª¬æ˜å¯èƒ½æ€§**: ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®å ±å‘Šã«é©ã—ãŸå‡ºåŠ›\n",
        "- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: æœ¬æ ¼é–‹ç™ºã¸ã®ç™ºå±•å¯èƒ½æ€§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "prompt-quality-metrics",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡æŒ‡æ¨™ã‚’å®šç¾©ã—ã¾ã—ãŸ\n",
            "\n",
            "=== è©•ä¾¡åŸºæº– ===\n",
            "â€¢ clarity: æŒ‡ç¤ºã®æ˜ç¢ºã•ã¨ç†è§£ã—ã‚„ã™ã•\n",
            "â€¢ specificity: å…·ä½“çš„ãªè¦æ±‚ã®æ˜ç¤ºåº¦\n",
            "â€¢ completeness: å¿…è¦ãªæƒ…å ±ã®ç¶²ç¾…æ€§\n",
            "â€¢ efficiency: ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã¨ç°¡æ½”æ€§\n",
            "â€¢ reproducibility: ä¸€è²«ã—ãŸçµæœã®å†ç¾æ€§\n",
            "\n",
            "ğŸ“ˆ ã‚µãƒ³ãƒ—ãƒ«ç·åˆã‚¹ã‚³ã‚¢: 7.8/10\n"
          ]
        }
      ],
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡æŒ‡æ¨™ã®å®šç¾©\n",
        "@dataclass\n",
        "class PromptQualityMetrics:\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡æŒ‡æ¨™\"\"\"\n",
        "    \n",
        "    # æ˜ç¢ºæ€§æŒ‡æ¨™ (1-10)\n",
        "    clarity: float = 0.0\n",
        "    \n",
        "    # å…·ä½“æ€§æŒ‡æ¨™ (1-10)\n",
        "    specificity: float = 0.0\n",
        "    \n",
        "    # å®Œå…¨æ€§æŒ‡æ¨™ (1-10)\n",
        "    completeness: float = 0.0\n",
        "    \n",
        "    # åŠ¹ç‡æ€§æŒ‡æ¨™ (1-10)\n",
        "    efficiency: float = 0.0\n",
        "    \n",
        "    # å†ç¾æ€§æŒ‡æ¨™ (1-10)\n",
        "    reproducibility: float = 0.0\n",
        "    \n",
        "    def overall_score(self) -> float:\n",
        "        \"\"\"ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—\"\"\"\n",
        "        scores = [self.clarity, self.specificity, self.completeness, \n",
        "                 self.efficiency, self.reproducibility]\n",
        "        return sum(scores) / len(scores)\n",
        "    \n",
        "    def to_dict(self) -> Dict[str, float]:\n",
        "        \"\"\"è¾æ›¸å½¢å¼ã«å¤‰æ›\"\"\"\n",
        "        return {\n",
        "            'clarity': self.clarity,\n",
        "            'specificity': self.specificity,\n",
        "            'completeness': self.completeness,\n",
        "            'efficiency': self.efficiency,\n",
        "            'reproducibility': self.reproducibility,\n",
        "            'overall': self.overall_score()\n",
        "        }\n",
        "\n",
        "# è©•ä¾¡åŸºæº–ã®èª¬æ˜\n",
        "evaluation_criteria = {\n",
        "    'clarity': 'æŒ‡ç¤ºã®æ˜ç¢ºã•ã¨ç†è§£ã—ã‚„ã™ã•',\n",
        "    'specificity': 'å…·ä½“çš„ãªè¦æ±‚ã®æ˜ç¤ºåº¦',\n",
        "    'completeness': 'å¿…è¦ãªæƒ…å ±ã®ç¶²ç¾…æ€§',\n",
        "    'efficiency': 'ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã¨ç°¡æ½”æ€§',\n",
        "    'reproducibility': 'ä¸€è²«ã—ãŸçµæœã®å†ç¾æ€§'\n",
        "}\n",
        "\n",
        "print(\"ğŸ“Š ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡æŒ‡æ¨™ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(\"\\n=== è©•ä¾¡åŸºæº– ===\")\n",
        "for key, desc in evaluation_criteria.items():\n",
        "    print(f\"â€¢ {key}: {desc}\")\n",
        "\n",
        "# ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡ã®è¡¨ç¤º\n",
        "sample_metrics = PromptQualityMetrics(\n",
        "    clarity=8.5,\n",
        "    specificity=7.0,\n",
        "    completeness=9.0,\n",
        "    efficiency=6.5,\n",
        "    reproducibility=8.0\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ ã‚µãƒ³ãƒ—ãƒ«ç·åˆã‚¹ã‚³ã‚¢: {sample_metrics.overall_score():.1f}/10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "prompt-pattern-analysis",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ AIåˆ†é‡åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©ã—ã¾ã—ãŸ\n",
            "\n",
            "=== ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§ ===\n",
            "\n",
            "ğŸ”¸ data_analysis:\n",
            "  èª¬æ˜: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»å¯è¦–åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
            "  è¦ç´ æ•°: 5å€‹\n",
            "  ä¸»è¦è¦ç´ : ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®æŒ‡å®š, åˆ†æç›®çš„ã®æ˜ç¢ºåŒ–, å‡ºåŠ›å½¢å¼ã®å®šç¾©...\n",
            "\n",
            "ğŸ”¸ image_recognition:\n",
            "  èª¬æ˜: ç”»åƒèªè­˜ãƒ»åˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
            "  è¦ç´ æ•°: 5å€‹\n",
            "  ä¸»è¦è¦ç´ : ç”»åƒã‚¿ã‚¤ãƒ—ã®æŒ‡å®š, èªè­˜å¯¾è±¡ã®å®šç¾©, ç²¾åº¦è¦ä»¶...\n",
            "\n",
            "ğŸ”¸ text_processing:\n",
            "  èª¬æ˜: ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ»NLPãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
            "  è¦ç´ æ•°: 5å€‹\n",
            "  ä¸»è¦è¦ç´ : ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å®šç¾©, å‡¦ç†ã‚¿ã‚¹ã‚¯ã®æŒ‡å®š, å‡ºåŠ›æ§‹é€ ã®æ˜ç¤º...\n",
            "\n",
            "ğŸ”¸ requirements_analysis:\n",
            "  èª¬æ˜: è¦ä»¶å®šç¾©æ”¯æ´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
            "  è¦ç´ æ•°: 5å€‹\n",
            "  ä¸»è¦è¦ç´ : ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼å®šç¾©, æ©Ÿèƒ½è¦ä»¶ã®æŠ½å‡º, éæ©Ÿèƒ½è¦ä»¶ã®ç‰¹å®š...\n",
            "\n",
            "ğŸ’¡ ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™\n"
          ]
        }
      ],
      "source": [
        "# AIåˆ†é‡åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\n",
        "prompt_patterns = {\n",
        "    'data_analysis': {\n",
        "        'description': 'ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»å¯è¦–åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ',\n",
        "        'key_elements': [\n",
        "            'ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®æŒ‡å®š',\n",
        "            'åˆ†æç›®çš„ã®æ˜ç¢ºåŒ–',\n",
        "            'å‡ºåŠ›å½¢å¼ã®å®šç¾©',\n",
        "            'çµ±è¨ˆæ‰‹æ³•ã®æŒ‡å®š',\n",
        "            'å¯è¦–åŒ–è¦ä»¶'\n",
        "        ],\n",
        "        'example_template': '''\n",
        "ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¿ã‚¹ã‚¯:\n",
        "- ãƒ‡ãƒ¼ã‚¿: {data_description}\n",
        "- ç›®çš„: {analysis_objective}\n",
        "- æ‰‹æ³•: {statistical_methods}\n",
        "- å‡ºåŠ›: {output_format}\n",
        "- åˆ¶ç´„: {constraints}\n",
        "        '''\n",
        "    },\n",
        "    'image_recognition': {\n",
        "        'description': 'ç”»åƒèªè­˜ãƒ»åˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ',\n",
        "        'key_elements': [\n",
        "            'ç”»åƒã‚¿ã‚¤ãƒ—ã®æŒ‡å®š',\n",
        "            'èªè­˜å¯¾è±¡ã®å®šç¾©',\n",
        "            'ç²¾åº¦è¦ä»¶',\n",
        "            'å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ',\n",
        "            'ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°'\n",
        "        ],\n",
        "        'example_template': '''\n",
        "ç”»åƒèªè­˜ã‚¿ã‚¹ã‚¯:\n",
        "- ç”»åƒã‚¿ã‚¤ãƒ—: {image_type}\n",
        "- èªè­˜å¯¾è±¡: {recognition_targets}\n",
        "- ç²¾åº¦è¦ä»¶: {accuracy_requirements}\n",
        "- å‡ºåŠ›å½¢å¼: {output_structure}\n",
        "- ä¾‹å¤–å‡¦ç†: {error_handling}\n",
        "        '''\n",
        "    },\n",
        "    'text_processing': {\n",
        "        'description': 'ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ»NLPãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ',\n",
        "        'key_elements': [\n",
        "            'ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å®šç¾©',\n",
        "            'å‡¦ç†ã‚¿ã‚¹ã‚¯ã®æŒ‡å®š',\n",
        "            'å‡ºåŠ›æ§‹é€ ã®æ˜ç¤º',\n",
        "            'å“è³ªåŸºæº–ã®è¨­å®š',\n",
        "            'è¨€èªãƒ»æ–‡ä½“ã®æŒ‡å®š'\n",
        "        ],\n",
        "        'example_template': '''\n",
        "ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¿ã‚¹ã‚¯:\n",
        "- å…¥åŠ›: {input_text_format}\n",
        "- å‡¦ç†: {processing_tasks}\n",
        "- å‡ºåŠ›: {output_structure}\n",
        "- å“è³ª: {quality_criteria}\n",
        "- è¨€èª: {language_style}\n",
        "        '''\n",
        "    },\n",
        "    'requirements_analysis': {\n",
        "        'description': 'è¦ä»¶å®šç¾©æ”¯æ´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ',\n",
        "        'key_elements': [\n",
        "            'ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼å®šç¾©',\n",
        "            'æ©Ÿèƒ½è¦ä»¶ã®æŠ½å‡º',\n",
        "            'éæ©Ÿèƒ½è¦ä»¶ã®ç‰¹å®š',\n",
        "            'åˆ¶ç´„æ¡ä»¶ã®æ˜ç¤º',\n",
        "            'å„ªå…ˆåº¦ã®è¨­å®š'\n",
        "        ],\n",
        "        'example_template': '''\n",
        "è¦ä»¶åˆ†æã‚¿ã‚¹ã‚¯:\n",
        "- å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ : {system_description}\n",
        "- ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼: {stakeholders}\n",
        "- æ©Ÿèƒ½è¦ä»¶: {functional_requirements}\n",
        "- éæ©Ÿèƒ½è¦ä»¶: {non_functional_requirements}\n",
        "- åˆ¶ç´„æ¡ä»¶: {constraints}\n",
        "        '''\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"ğŸ¯ AIåˆ†é‡åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(\"\\n=== ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§ ===\")\n",
        "for pattern_name, pattern_info in prompt_patterns.items():\n",
        "    print(f\"\\nğŸ”¸ {pattern_name}:\")\n",
        "    print(f\"  èª¬æ˜: {pattern_info['description']}\")\n",
        "    print(f\"  è¦ç´ æ•°: {len(pattern_info['key_elements'])}å€‹\")\n",
        "    print(f\"  ä¸»è¦è¦ç´ : {', '.join(pattern_info['key_elements'][:3])}...\")\n",
        "\n",
        "print(\"\\nğŸ’¡ ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "prompt-components",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹æˆ:\n",
            "å½¹å‰²: ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶\n",
            "\n",
            "èƒŒæ™¯: ECã‚µã‚¤ãƒˆã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿åˆ†æã‚’è¡Œã„ã€æ”¹å–„ç‚¹ã‚’ç‰¹å®šã™ã‚‹\n",
            "\n",
            "æŒ‡ç¤º: æœˆåˆ¥å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã€å­£ç¯€æ€§ã¨ä¸»è¦ãªå¤‰å‹•è¦å› ã‚’ç‰¹å®šã—ã¦ãã ã•ã„\n",
            "\n",
            "å‡ºåŠ›å½¢å¼: JSONå½¢å¼ã§åˆ†æçµæœã€ã‚°ãƒ©ãƒ•èª¬æ˜ã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã‚ã‚‹\n",
            "\n",
            "ä¾‹ç¤º:\n",
            "1. 12æœˆã®å£²ä¸Šæ€¥å¢—ã¯å¹´æœ«ã‚»ãƒ¼ãƒ«åŠ¹æœ\n",
            "2. 3æœˆã®ä½ä¸‹ã¯æ–°å¹´åº¦æº–å‚™æœŸé–“ã®å½±éŸ¿\n",
            "\n",
            "åˆ¶ç´„:\n",
            "- çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼ã™ã‚‹ã“ã¨\n",
            "- éå»2å¹´é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨\n",
            "\n",
            "âœ… å¦¥å½“æ€§: å•é¡Œãªã—\n"
          ]
        }
      ],
      "source": [
        "# åŠ¹æœçš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹æˆè¦ç´ \n",
        "@dataclass\n",
        "class PromptComponents:\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹æˆè¦ç´ \"\"\"\n",
        "    \n",
        "    # å½¹å‰²å®šç¾© (Role)\n",
        "    role: str = \"\"\n",
        "    \n",
        "    # æ–‡è„ˆæƒ…å ± (Context)\n",
        "    context: str = \"\"\n",
        "    \n",
        "    # å…·ä½“çš„æŒ‡ç¤º (Instruction)\n",
        "    instruction: str = \"\"\n",
        "    \n",
        "    # å‡ºåŠ›å½¢å¼ (Format)\n",
        "    output_format: str = \"\"\n",
        "    \n",
        "    # ä¾‹ç¤º (Examples)\n",
        "    examples: List[str] = None\n",
        "    \n",
        "    # åˆ¶ç´„æ¡ä»¶ (Constraints)\n",
        "    constraints: List[str] = None\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        if self.examples is None:\n",
        "            self.examples = []\n",
        "        if self.constraints is None:\n",
        "            self.constraints = []\n",
        "    \n",
        "    def to_prompt(self) -> str:\n",
        "        \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—ã«å¤‰æ›\"\"\"\n",
        "        prompt_parts = []\n",
        "        \n",
        "        if self.role:\n",
        "            prompt_parts.append(f\"å½¹å‰²: {self.role}\")\n",
        "        \n",
        "        if self.context:\n",
        "            prompt_parts.append(f\"\\nèƒŒæ™¯: {self.context}\")\n",
        "        \n",
        "        if self.instruction:\n",
        "            prompt_parts.append(f\"\\næŒ‡ç¤º: {self.instruction}\")\n",
        "        \n",
        "        if self.output_format:\n",
        "            prompt_parts.append(f\"\\nå‡ºåŠ›å½¢å¼: {self.output_format}\")\n",
        "        \n",
        "        if self.examples:\n",
        "            prompt_parts.append(f\"\\nä¾‹ç¤º:\")\n",
        "            for i, example in enumerate(self.examples, 1):\n",
        "                prompt_parts.append(f\"{i}. {example}\")\n",
        "        \n",
        "        if self.constraints:\n",
        "            prompt_parts.append(f\"\\nåˆ¶ç´„:\")\n",
        "            for constraint in self.constraints:\n",
        "                prompt_parts.append(f\"- {constraint}\")\n",
        "        \n",
        "        return \"\\n\".join(prompt_parts)\n",
        "    \n",
        "    def validate(self) -> Tuple[bool, List[str]]:\n",
        "        \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯\"\"\"\n",
        "        issues = []\n",
        "        \n",
        "        if not self.instruction:\n",
        "            issues.append(\"å…·ä½“çš„æŒ‡ç¤ºãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "        \n",
        "        if not self.output_format:\n",
        "            issues.append(\"å‡ºåŠ›å½¢å¼ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "        \n",
        "        if len(self.instruction) < 10:\n",
        "            issues.append(\"æŒ‡ç¤ºãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
        "        \n",
        "        return len(issues) == 0, issues\n",
        "\n",
        "# ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹æˆã®ä½œæˆ\n",
        "sample_prompt = PromptComponents(\n",
        "    role=\"ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶\",\n",
        "    context=\"ECã‚µã‚¤ãƒˆã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿åˆ†æã‚’è¡Œã„ã€æ”¹å–„ç‚¹ã‚’ç‰¹å®šã™ã‚‹\",\n",
        "    instruction=\"æœˆåˆ¥å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã€å­£ç¯€æ€§ã¨ä¸»è¦ãªå¤‰å‹•è¦å› ã‚’ç‰¹å®šã—ã¦ãã ã•ã„\",\n",
        "    output_format=\"JSONå½¢å¼ã§åˆ†æçµæœã€ã‚°ãƒ©ãƒ•èª¬æ˜ã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã‚ã‚‹\",\n",
        "    examples=[\n",
        "        \"12æœˆã®å£²ä¸Šæ€¥å¢—ã¯å¹´æœ«ã‚»ãƒ¼ãƒ«åŠ¹æœ\",\n",
        "        \"3æœˆã®ä½ä¸‹ã¯æ–°å¹´åº¦æº–å‚™æœŸé–“ã®å½±éŸ¿\"\n",
        "    ],\n",
        "    constraints=[\n",
        "        \"çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼ã™ã‚‹ã“ã¨\",\n",
        "        \"éå»2å¹´é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯\n",
        "is_valid, validation_issues = sample_prompt.validate()\n",
        "\n",
        "print(\"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹æˆ:\")\n",
        "print(sample_prompt.to_prompt())\n",
        "print(f\"\\nâœ… å¦¥å½“æ€§: {'å•é¡Œãªã—' if is_valid else 'è¦ä¿®æ­£'}\")\n",
        "if validation_issues:\n",
        "    for issue in validation_issues:\n",
        "        print(f\"  âš ï¸ {issue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-3-templates",
      "metadata": {},
      "source": [
        "# 3. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "template-base-class",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ—ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã—ã¾ã—ãŸ\n",
            "ğŸ“‚ åˆ©ç”¨å¯èƒ½ã‚«ãƒ†ã‚´ãƒª: ['data_analysis', 'image_recognition', 'text_processing', 'requirements_analysis', 'general_poc']\n"
          ]
        }
      ],
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹\n",
        "from abc import ABC, abstractmethod\n",
        "from enum import Enum\n",
        "\n",
        "class PromptCategory(Enum):\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚«ãƒ†ã‚´ãƒª\"\"\"\n",
        "    DATA_ANALYSIS = \"data_analysis\"\n",
        "    IMAGE_RECOGNITION = \"image_recognition\"\n",
        "    TEXT_PROCESSING = \"text_processing\"\n",
        "    REQUIREMENTS_ANALYSIS = \"requirements_analysis\"\n",
        "    GENERAL_POC = \"general_poc\"\n",
        "\n",
        "class PromptTemplate(ABC):\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, category: PromptCategory, description: str):\n",
        "        self.name = name\n",
        "        self.category = category\n",
        "        self.description = description\n",
        "        self.created_at = datetime.now()\n",
        "        self.usage_count = 0\n",
        "    \n",
        "    @abstractmethod\n",
        "    def get_template(self) -> str:\n",
        "        \"\"\"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ–‡å­—åˆ—ã‚’å–å¾—\"\"\"\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def get_variables(self) -> List[str]:\n",
        "        \"\"\"å¿…è¦ãªå¤‰æ•°ãƒªã‚¹ãƒˆã‚’å–å¾—\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def generate_prompt(self, variables: Dict[str, str]) -> str:\n",
        "        \"\"\"å¤‰æ•°ã‚’ç½®æ›ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ\"\"\"\n",
        "        template = self.get_template()\n",
        "        \n",
        "        # å¿…è¦ãªå¤‰æ•°ã®ç¢ºèª\n",
        "        required_vars = set(self.get_variables())\n",
        "        provided_vars = set(variables.keys())\n",
        "        \n",
        "        missing_vars = required_vars - provided_vars\n",
        "        if missing_vars:\n",
        "            raise ValueError(f\"å¿…è¦ãªå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_vars}\")\n",
        "        \n",
        "        # å¤‰æ•°ç½®æ›\n",
        "        try:\n",
        "            prompt = template.format(**variables)\n",
        "            self.usage_count += 1\n",
        "            return prompt\n",
        "        except KeyError as e:\n",
        "            raise ValueError(f\"å¤‰æ•°ã®ç½®æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
        "    \n",
        "    def get_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæƒ…å ±ã‚’å–å¾—\"\"\"\n",
        "        return {\n",
        "            'name': self.name,\n",
        "            'category': self.category.value,\n",
        "            'description': self.description,\n",
        "            'variables': self.get_variables(),\n",
        "            'created_at': self.created_at.isoformat(),\n",
        "            'usage_count': self.usage_count\n",
        "        }\n",
        "\n",
        "print(\"ğŸ—ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(f\"ğŸ“‚ åˆ©ç”¨å¯èƒ½ã‚«ãƒ†ã‚´ãƒª: {[cat.value for cat in PromptCategory]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "data-analysis-template",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ PoCç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ\n",
            "\n",
            "ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æPoC:\n",
            "  å¿…è¦å¤‰æ•°: 5å€‹\n",
            "  ã‚«ãƒ†ã‚´ãƒª: data_analysis\n",
            "\n",
            "ğŸ–¼ï¸ ç”»åƒèªè­˜PoC:\n",
            "  å¿…è¦å¤‰æ•°: 6å€‹\n",
            "  ã‚«ãƒ†ã‚´ãƒª: image_recognition\n"
          ]
        }
      ],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿åˆ†æPoCç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "class DataAnalysisTemplate(PromptTemplate):\n",
        "    \"\"\"ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"ãƒ‡ãƒ¼ã‚¿åˆ†æPoC\",\n",
        "            category=PromptCategory.DATA_ANALYSIS,\n",
        "            description=\"ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\"\n",
        "        )\n",
        "    \n",
        "    def get_template(self) -> str:\n",
        "        return \"\"\"\n",
        "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚\n",
        "\n",
        "ã€åˆ†æå¯¾è±¡ã€‘\n",
        "{data_description}\n",
        "\n",
        "ã€åˆ†æç›®çš„ã€‘\n",
        "{analysis_objective}\n",
        "\n",
        "ã€åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã€‘\n",
        "{available_data}\n",
        "\n",
        "ã€æœŸå¾…ã™ã‚‹åˆ†ææ‰‹æ³•ã€‘\n",
        "{analysis_methods}\n",
        "\n",
        "ã€å‡ºåŠ›è¦ä»¶ã€‘\n",
        "ä»¥ä¸‹ã®å½¢å¼ã§åˆ†æçµæœã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š\n",
        "1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆè¦ç‚¹ã‚’3ç‚¹ä»¥å†…ï¼‰\n",
        "2. ä¸»è¦ãªç™ºè¦‹äº‹é …ï¼ˆçµ±è¨ˆå€¤ã‚’å«ã‚€ï¼‰\n",
        "3. ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ææ¡ˆï¼ˆã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã¨å†…å®¹ï¼‰\n",
        "4. ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿ã®è©•ä¾¡\n",
        "5. æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³\n",
        "\n",
        "ã€åˆ¶ç´„æ¡ä»¶ã€‘\n",
        "- {constraints}\n",
        "- çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’å¿…ãšæ¤œè¨¼ã™ã‚‹ã“ã¨\n",
        "- ãƒ“ã‚¸ãƒã‚¹æ‹…å½“è€…ã«ã‚‚ç†è§£ã§ãã‚‹å¹³æ˜“ãªèª¬æ˜ã‚’å«ã‚ã‚‹ã“ã¨\n",
        "\n",
        "åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚\n",
        "        \"\"\".strip()\n",
        "    \n",
        "    def get_variables(self) -> List[str]:\n",
        "        return [\n",
        "            'data_description',\n",
        "            'analysis_objective', \n",
        "            'available_data',\n",
        "            'analysis_methods',\n",
        "            'constraints'\n",
        "        ]\n",
        "\n",
        "# ç”»åƒèªè­˜PoCç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "class ImageRecognitionTemplate(PromptTemplate):\n",
        "    \"\"\"ç”»åƒèªè­˜ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"ç”»åƒèªè­˜PoC\",\n",
        "            category=PromptCategory.IMAGE_RECOGNITION,\n",
        "            description=\"ç”»åƒèªè­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\"\n",
        "        )\n",
        "    \n",
        "    def get_template(self) -> str:\n",
        "        return \"\"\"\n",
        "ã‚ãªãŸã¯ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ã€å¯¾è±¡ç”»åƒã€‘\n",
        "{image_types}\n",
        "\n",
        "ã€èªè­˜ã‚¿ã‚¹ã‚¯ã€‘\n",
        "{recognition_task}\n",
        "\n",
        "ã€èªè­˜å¯¾è±¡ã€‘\n",
        "{target_objects}\n",
        "\n",
        "ã€ç²¾åº¦è¦ä»¶ã€‘\n",
        "{accuracy_requirements}\n",
        "\n",
        "ã€åˆ©ç”¨ç’°å¢ƒã€‘\n",
        "{deployment_environment}\n",
        "\n",
        "ã€å‡ºåŠ›å½¢å¼ã€‘\n",
        "ä»¥ä¸‹ã®JSONå½¢å¼ã§çµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n",
        "```json\n",
        "{{\n",
        "  \"detected_objects\": [\n",
        "    {{\n",
        "      \"class\": \"ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå\",\n",
        "      \"confidence\": 0.95,\n",
        "      \"bbox\": [x1, y1, x2, y2]\n",
        "    }}\n",
        "  ],\n",
        "  \"processing_time\": \"å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰\",\n",
        "  \"model_info\": \"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æƒ…å ±\"\n",
        "}}\n",
        "```\n",
        "\n",
        "ã€åˆ¶ç´„æ¡ä»¶ã€‘\n",
        "- {constraints}\n",
        "- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†è¦ä»¶ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨\n",
        "- èª¤æ¤œå‡ºã®å‡¦ç†æ–¹æ³•ã‚’æ˜ç¢ºã«ã™ã‚‹ã“ã¨\n",
        "\n",
        "ç”»åƒèªè­˜ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
        "        \"\"\".strip()\n",
        "    \n",
        "    def get_variables(self) -> List[str]:\n",
        "        return [\n",
        "            'image_types',\n",
        "            'recognition_task',\n",
        "            'target_objects',\n",
        "            'accuracy_requirements',\n",
        "            'deployment_environment',\n",
        "            'constraints'\n",
        "        ]\n",
        "\n",
        "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨ä¾‹\n",
        "data_template = DataAnalysisTemplate()\n",
        "image_template = ImageRecognitionTemplate()\n",
        "\n",
        "print(\"ğŸ¯ PoCç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ\")\n",
        "print(f\"\\nğŸ“Š {data_template.name}:\")\n",
        "print(f\"  å¿…è¦å¤‰æ•°: {len(data_template.get_variables())}å€‹\")\n",
        "print(f\"  ã‚«ãƒ†ã‚´ãƒª: {data_template.category.value}\")\n",
        "\n",
        "print(f\"\\nğŸ–¼ï¸ {image_template.name}:\")\n",
        "print(f\"  å¿…è¦å¤‰æ•°: {len(image_template.get_variables())}å€‹\")\n",
        "print(f\"  ã‚«ãƒ†ã‚´ãƒª: {image_template.category.value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "text-processing-template",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ è¿½åŠ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ\n",
            "\n",
            "ğŸ”¤ ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†PoC:\n",
            "  å¿…è¦å¤‰æ•°: ['text_type', 'text_description', 'processing_tasks', 'processing_requirements', 'quality_criteria', 'language_style', 'constraints']\n",
            "\n",
            "ğŸ“‹ è¦ä»¶å®šç¾©æ”¯æ´:\n",
            "  å¿…è¦å¤‰æ•°æ•°: 6å€‹\n",
            "  ç”¨é€”: ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶æ•´ç†\n"
          ]
        }
      ],
      "source": [
        "# ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†PoCç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "class TextProcessingTemplate(PromptTemplate):\n",
        "    \"\"\"ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†PoC\",\n",
        "            category=PromptCategory.TEXT_PROCESSING,\n",
        "            description=\"è‡ªç„¶è¨€èªå‡¦ç†ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\"\n",
        "        )\n",
        "    \n",
        "    def get_template(self) -> str:\n",
        "        return \"\"\"\n",
        "ã‚ãªãŸã¯è‡ªç„¶è¨€èªå‡¦ç†ã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ã€å‡¦ç†å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆã€‘\n",
        "{text_type}: {text_description}\n",
        "\n",
        "ã€å‡¦ç†ã‚¿ã‚¹ã‚¯ã€‘\n",
        "{processing_tasks}\n",
        "\n",
        "ã€å‡¦ç†è¦ä»¶ã€‘\n",
        "{processing_requirements}\n",
        "\n",
        "ã€å“è³ªåŸºæº–ã€‘\n",
        "{quality_criteria}\n",
        "\n",
        "ã€å‡ºåŠ›è¨€èªãƒ»æ–‡ä½“ã€‘\n",
        "{language_style}\n",
        "\n",
        "ã€å‡ºåŠ›æ§‹é€ ã€‘\n",
        "ä»¥ä¸‹ã®å½¢å¼ã§çµæœã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š\n",
        "```json\n",
        "{{\n",
        "  \"original_text\": \"å…ƒãƒ†ã‚­ã‚¹ãƒˆï¼ˆæŠœç²‹ï¼‰\",\n",
        "  \"processing_results\": {{\n",
        "    \"task1\": \"çµæœ1\",\n",
        "    \"task2\": \"çµæœ2\"\n",
        "  }},\n",
        "  \"confidence_scores\": {{\n",
        "    \"task1\": 0.92,\n",
        "    \"task2\": 0.88\n",
        "  }},\n",
        "  \"processing_notes\": \"å‡¦ç†æ™‚ã®æ³¨æ„ç‚¹ã‚„èª²é¡Œ\",\n",
        "  \"improvement_suggestions\": \"æ”¹å–„ææ¡ˆ\"\n",
        "}}\n",
        "```\n",
        "\n",
        "ã€åˆ¶ç´„æ¡ä»¶ã€‘\n",
        "- {constraints}\n",
        "- æ–‡è„ˆã®ç†è§£ã‚’é‡è¦–ã™ã‚‹ã“ã¨\n",
        "- ã‚ã„ã¾ã„ãªè¡¨ç¾ã¯é©åˆ‡ã«è§£é‡ˆã™ã‚‹ã“ã¨\n",
        "\n",
        "ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚\n",
        "        \"\"\".strip()\n",
        "    \n",
        "    def get_variables(self) -> List[str]:\n",
        "        return [\n",
        "            'text_type',\n",
        "            'text_description',\n",
        "            'processing_tasks',\n",
        "            'processing_requirements',\n",
        "            'quality_criteria',\n",
        "            'language_style',\n",
        "            'constraints'\n",
        "        ]\n",
        "\n",
        "# è¦ä»¶å®šç¾©æ”¯æ´ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
        "class RequirementsAnalysisTemplate(PromptTemplate):\n",
        "    \"\"\"è¦ä»¶å®šç¾©æ”¯æ´ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"è¦ä»¶å®šç¾©æ”¯æ´\",\n",
        "            category=PromptCategory.REQUIREMENTS_ANALYSIS,\n",
        "            description=\"ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶å®šç¾©ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\"\n",
        "        )\n",
        "    \n",
        "    def get_template(self) -> str:\n",
        "        return \"\"\"\n",
        "ã‚ãªãŸã¯ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒŠãƒªã‚¹ãƒˆã¨ã—ã¦ã€è¦ä»¶å®šç¾©ã‚’æ”¯æ´ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ã€‘\n",
        "{system_description}\n",
        "\n",
        "ã€ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã€‘\n",
        "{stakeholders}\n",
        "\n",
        "ã€ãƒ“ã‚¸ãƒã‚¹èƒŒæ™¯ã€‘\n",
        "{business_context}\n",
        "\n",
        "ã€ç¾çŠ¶ã®èª²é¡Œã€‘\n",
        "{current_issues}\n",
        "\n",
        "ã€æœŸå¾…ã™ã‚‹åŠ¹æœã€‘\n",
        "{expected_benefits}\n",
        "\n",
        "ã€åˆ¶ç´„æ¡ä»¶ã€‘\n",
        "{constraints}\n",
        "\n",
        "ã€è¦æ±‚äº‹é …ã€‘\n",
        "ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è¦ä»¶ã‚’æ•´ç†ã—ã¦ãã ã•ã„ï¼š\n",
        "\n",
        "1. **æ©Ÿèƒ½è¦ä»¶**\n",
        "   - å¿…é ˆæ©Ÿèƒ½ï¼ˆMustHaveï¼‰\n",
        "   - é‡è¦æ©Ÿèƒ½ï¼ˆShouldHaveï¼‰\n",
        "   - ã‚ã‚‹ã¨è‰¯ã„æ©Ÿèƒ½ï¼ˆCouldHaveï¼‰\n",
        "\n",
        "2. **éæ©Ÿèƒ½è¦ä»¶**\n",
        "   - æ€§èƒ½è¦ä»¶ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼‰\n",
        "   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶\n",
        "   - å¯ç”¨æ€§ãƒ»ä¿¡é ¼æ€§è¦ä»¶\n",
        "   - é‹ç”¨ãƒ»ä¿å®ˆè¦ä»¶\n",
        "\n",
        "3. **æŠ€è¡“è¦ä»¶**\n",
        "   - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ–¹é‡\n",
        "   - ã‚¤ãƒ³ãƒ•ãƒ©è¦ä»¶\n",
        "   - é–‹ç™ºãƒ»é‹ç”¨ãƒ„ãƒ¼ãƒ«\n",
        "\n",
        "4. **ãƒªã‚¹ã‚¯åˆ†æ**\n",
        "   - æŠ€è¡“çš„ãƒªã‚¹ã‚¯\n",
        "   - ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒªã‚¹ã‚¯\n",
        "   - é‹ç”¨ãƒªã‚¹ã‚¯\n",
        "\n",
        "å„è¦ä»¶ã«ã¯å„ªå…ˆåº¦ã€å®Ÿç¾é›£æ˜“åº¦ã€å·¥æ•°è¦‹ç©ã‚‚ã‚Šã‚’å«ã‚ã¦ãã ã•ã„ã€‚\n",
        "        \"\"\".strip()\n",
        "    \n",
        "    def get_variables(self) -> List[str]:\n",
        "        return [\n",
        "            'system_description',\n",
        "            'stakeholders',\n",
        "            'business_context',\n",
        "            'current_issues',\n",
        "            'expected_benefits',\n",
        "            'constraints'\n",
        "        ]\n",
        "\n",
        "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½¿ç”¨ä¾‹\n",
        "text_template = TextProcessingTemplate()\n",
        "req_template = RequirementsAnalysisTemplate()\n",
        "\n",
        "print(\"ğŸ“ è¿½åŠ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ\")\n",
        "print(f\"\\nğŸ”¤ {text_template.name}:\")\n",
        "print(f\"  å¿…è¦å¤‰æ•°: {text_template.get_variables()}\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ {req_template.name}:\")\n",
        "print(f\"  å¿…è¦å¤‰æ•°æ•°: {len(req_template.get_variables())}å€‹\")\n",
        "print(f\"  ç”¨é€”: ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶æ•´ç†\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "template-manager",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ—‚ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ\n",
            "ğŸ“Š ç™»éŒ²æ¸ˆã¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: 4\n",
            "\n",
            "=== çµ±è¨ˆæƒ…å ± ===\n",
            "ç·ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: 4\n",
            "ã‚«ãƒ†ã‚´ãƒªåˆ¥:\n",
            "  data_analysis: 1å€‹\n",
            "  image_recognition: 1å€‹\n",
            "  text_processing: 1å€‹\n",
            "  requirements_analysis: 1å€‹\n",
            "\n",
            "=== åˆ©ç”¨å¯èƒ½ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ===\n",
            "ğŸ”¸ ãƒ‡ãƒ¼ã‚¿åˆ†æPoC (data_analysis)\n",
            "  èª¬æ˜: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
            "  å¿…è¦å¤‰æ•°: 5å€‹\n",
            "ğŸ”¸ ç”»åƒèªè­˜PoC (image_recognition)\n",
            "  èª¬æ˜: ç”»åƒèªè­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
            "  å¿…è¦å¤‰æ•°: 6å€‹\n",
            "ğŸ”¸ ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†PoC (text_processing)\n",
            "  èª¬æ˜: è‡ªç„¶è¨€èªå‡¦ç†ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
            "  å¿…è¦å¤‰æ•°: 7å€‹\n",
            "ğŸ”¸ è¦ä»¶å®šç¾©æ”¯æ´ (requirements_analysis)\n",
            "  èª¬æ˜: ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶å®šç¾©ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
            "  å¿…è¦å¤‰æ•°: 6å€‹\n"
          ]
        }
      ],
      "source": [
        "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹\n",
        "class TemplateManager:\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.templates: Dict[str, PromptTemplate] = {}\n",
        "        self._initialize_default_templates()\n",
        "    \n",
        "    def _initialize_default_templates(self):\n",
        "        \"\"\"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆæœŸåŒ–\"\"\"\n",
        "        default_templates = [\n",
        "            DataAnalysisTemplate(),\n",
        "            ImageRecognitionTemplate(),\n",
        "            TextProcessingTemplate(),\n",
        "            RequirementsAnalysisTemplate()\n",
        "        ]\n",
        "        \n",
        "        for template in default_templates:\n",
        "            self.templates[template.name] = template\n",
        "    \n",
        "    def add_template(self, template: PromptTemplate):\n",
        "        \"\"\"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿½åŠ \"\"\"\n",
        "        self.templates[template.name] = template\n",
        "    \n",
        "    def get_template(self, name: str) -> Optional[PromptTemplate]:\n",
        "        \"\"\"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—\"\"\"\n",
        "        return self.templates.get(name)\n",
        "    \n",
        "    def list_templates(self, category: Optional[PromptCategory] = None) -> List[Dict[str, Any]]:\n",
        "        \"\"\"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—\"\"\"\n",
        "        templates = list(self.templates.values())\n",
        "        \n",
        "        if category:\n",
        "            templates = [t for t in templates if t.category == category]\n",
        "        \n",
        "        return [t.get_info() for t in templates]\n",
        "    \n",
        "    def generate_prompt(self, template_name: str, variables: Dict[str, str]) -> str:\n",
        "        \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ\"\"\"\n",
        "        template = self.get_template(template_name)\n",
        "        if not template:\n",
        "            raise ValueError(f\"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{template_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "        \n",
        "        return template.generate_prompt(variables)\n",
        "    \n",
        "    def get_usage_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"ä½¿ç”¨çµ±è¨ˆã‚’å–å¾—\"\"\"\n",
        "        stats = {\n",
        "            'total_templates': len(self.templates),\n",
        "            'templates_by_category': {},\n",
        "            'most_used': None,\n",
        "            'usage_details': []\n",
        "        }\n",
        "        \n",
        "        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ\n",
        "        for template in self.templates.values():\n",
        "            category = template.category.value\n",
        "            if category not in stats['templates_by_category']:\n",
        "                stats['templates_by_category'][category] = 0\n",
        "            stats['templates_by_category'][category] += 1\n",
        "        \n",
        "        # ä½¿ç”¨å›æ•°é›†è¨ˆ\n",
        "        if self.templates:\n",
        "            most_used = max(self.templates.values(), key=lambda t: t.usage_count)\n",
        "            stats['most_used'] = {\n",
        "                'name': most_used.name,\n",
        "                'usage_count': most_used.usage_count\n",
        "            }\n",
        "            \n",
        "            stats['usage_details'] = [\n",
        "                {\n",
        "                    'name': t.name,\n",
        "                    'category': t.category.value,\n",
        "                    'usage_count': t.usage_count\n",
        "                }\n",
        "                for t in sorted(self.templates.values(), key=lambda t: t.usage_count, reverse=True)\n",
        "            ]\n",
        "        \n",
        "        return stats\n",
        "\n",
        "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ\n",
        "template_manager = TemplateManager()\n",
        "\n",
        "print(\"ğŸ—‚ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ\")\n",
        "print(f\"ğŸ“Š ç™»éŒ²æ¸ˆã¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: {len(template_manager.templates)}\")\n",
        "\n",
        "# ä½¿ç”¨çµ±è¨ˆè¡¨ç¤º\n",
        "stats = template_manager.get_usage_stats()\n",
        "print(\"\\n=== çµ±è¨ˆæƒ…å ± ===\")\n",
        "print(f\"ç·ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: {stats['total_templates']}\")\n",
        "print(\"ã‚«ãƒ†ã‚´ãƒªåˆ¥:\")\n",
        "for category, count in stats['templates_by_category'].items():\n",
        "    print(f\"  {category}: {count}å€‹\")\n",
        "\n",
        "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§è¡¨ç¤º\n",
        "print(\"\\n=== åˆ©ç”¨å¯èƒ½ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ===\")\n",
        "for template_info in template_manager.list_templates():\n",
        "    print(f\"ğŸ”¸ {template_info['name']} ({template_info['category']})\")\n",
        "    print(f\"  èª¬æ˜: {template_info['description']}\")\n",
        "    print(f\"  å¿…è¦å¤‰æ•°: {len(template_info['variables'])}å€‹\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "custom-template-creation",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ› ï¸ ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã—ãŸ\n",
            "âœ… ã‚µãƒ³ãƒ—ãƒ«ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ 'APIãƒ†ã‚¹ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' ã‚’è¿½åŠ \n",
            "ğŸ“Š ç¾åœ¨ã®ç·ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: 5\n",
            "\n",
            "=== æ›´æ–°ã•ã‚ŒãŸçµ±è¨ˆ ===\n",
            "data_analysis: 1å€‹\n",
            "image_recognition: 1å€‹\n",
            "text_processing: 1å€‹\n",
            "requirements_analysis: 1å€‹\n",
            "general_poc: 1å€‹\n"
          ]
        }
      ],
      "source": [
        "# ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆæ©Ÿèƒ½\n",
        "class CustomTemplate(PromptTemplate):\n",
        "    \"\"\"ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, category: PromptCategory, description: str, \n",
        "                 template_content: str, variables: List[str]):\n",
        "        super().__init__(name, category, description)\n",
        "        self.template_content = template_content\n",
        "        self.variables = variables\n",
        "    \n",
        "    def get_template(self) -> str:\n",
        "        return self.template_content\n",
        "    \n",
        "    def get_variables(self) -> List[str]:\n",
        "        return self.variables\n",
        "\n",
        "def create_custom_template(name: str, category: str, description: str, \n",
        "                          template_content: str, variables: List[str]) -> CustomTemplate:\n",
        "    \"\"\"ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ\"\"\"\n",
        "    try:\n",
        "        category_enum = PromptCategory(category)\n",
        "    except ValueError:\n",
        "        raise ValueError(f\"ç„¡åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã§ã™: {category}. åˆ©ç”¨å¯èƒ½: {[c.value for c in PromptCategory]}\")\n",
        "    \n",
        "    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…ã®å¤‰æ•°ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ¤œè¨¼\n",
        "    import re\n",
        "    template_vars = set(re.findall(r'\\{(\\w+)\\}', template_content))\n",
        "    provided_vars = set(variables)\n",
        "    \n",
        "    missing_vars = template_vars - provided_vars\n",
        "    if missing_vars:\n",
        "        print(f\"âš ï¸  ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…ã®å¤‰æ•° {missing_vars} ãŒå¤‰æ•°ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "    \n",
        "    extra_vars = provided_vars - template_vars\n",
        "    if extra_vars:\n",
        "        print(f\"ğŸ’¡ å¤‰æ•°ãƒªã‚¹ãƒˆã® {extra_vars} ãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "    \n",
        "    return CustomTemplate(name, category_enum, description, template_content, variables)\n",
        "\n",
        "# ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆä¾‹\n",
        "sample_custom_template = create_custom_template(\n",
        "    name=\"APIãƒ†ã‚¹ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\",\n",
        "    category=\"general_poc\",\n",
        "    description=\"APIæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆç”¨\",\n",
        "    template_content=\"\"\"\n",
        "ã‚ãªãŸã¯APIãƒ†ã‚¹ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ã€å¯¾è±¡APIã€‘\n",
        "{api_endpoint}: {api_description}\n",
        "\n",
        "ã€ãƒ†ã‚¹ãƒˆè¦³ç‚¹ã€‘\n",
        "{test_scenarios}\n",
        "\n",
        "ã€æœŸå¾…ã™ã‚‹å“è³ªã€‘\n",
        "{quality_requirements}\n",
        "\n",
        "ä»¥ä¸‹ã®å½¢å¼ã§ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\n",
        "1. æ­£å¸¸ç³»ãƒ†ã‚¹ãƒˆ\n",
        "2. ç•°å¸¸ç³»ãƒ†ã‚¹ãƒˆ  \n",
        "3. å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ\n",
        "4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ\n",
        "\n",
        "å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã«ã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€æœŸå¾…çµæœã€æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚\n",
        "    \"\"\".strip(),\n",
        "    variables=[\"api_endpoint\", \"api_description\", \"test_scenarios\", \"quality_requirements\"]\n",
        ")\n",
        "\n",
        "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«è¿½åŠ \n",
        "template_manager.add_template(sample_custom_template)\n",
        "\n",
        "print(\"ğŸ› ï¸ ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã—ãŸ\")\n",
        "print(f\"âœ… ã‚µãƒ³ãƒ—ãƒ«ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{sample_custom_template.name}' ã‚’è¿½åŠ \")\n",
        "print(f\"ğŸ“Š ç¾åœ¨ã®ç·ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: {len(template_manager.templates)}\")\n",
        "\n",
        "# æ›´æ–°ã•ã‚ŒãŸçµ±è¨ˆã‚’è¡¨ç¤º\n",
        "updated_stats = template_manager.get_usage_stats()\n",
        "print(\"\\n=== æ›´æ–°ã•ã‚ŒãŸçµ±è¨ˆ ===\")\n",
        "for category, count in updated_stats['templates_by_category'].items():\n",
        "    print(f\"{category}: {count}å€‹\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-4-langgraph",
      "metadata": {},
      "source": [
        "# 4. LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "langgraph-state-definition",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… LangGraphãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†\n",
            "ğŸ”„ LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹ã‚’å®šç¾©ã—ã¾ã—ãŸ\n",
            "\n",
            "=== çŠ¶æ…‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ===\n",
            "ğŸ“ åŸºæœ¬æƒ…å ±: user_request, context\n",
            "ğŸ’­ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: initial_prompt, current_prompt, improved_prompt\n",
            "ğŸ“Š è©•ä¾¡: quality_scores, evaluation_feedback, improvement_suggestions\n",
            "âš™ï¸ åˆ¶å¾¡: iteration_count, max_iterations, is_satisfactory\n",
            "ğŸ“œ å±¥æ­´: messages, processing_logs\n"
          ]
        }
      ],
      "source": [
        "# LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”¨ã®çŠ¶æ…‹å®šç¾©\n",
        "from typing import TypedDict, Annotated, Dict, List, Optional, Any\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# LangChain/LangGraphé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰\n",
        "try:\n",
        "    from langgraph.graph.message import add_messages\n",
        "    from langchain.schema import BaseMessage\n",
        "    print(\"âœ… LangGraphãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ LangGraphãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯åˆ©ç”¨ä¸å¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\")\n",
        "    # ãƒ€ãƒŸãƒ¼ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ç”¨ï¼‰\n",
        "    class BaseMessage:\n",
        "        pass\n",
        "    def add_messages(x):\n",
        "        return x\n",
        "\n",
        "class PromptWorkflowState(TypedDict):\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çŠ¶æ…‹\"\"\"\n",
        "    \n",
        "    # åŸºæœ¬æƒ…å ±\n",
        "    user_request: str  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚\n",
        "    context: str       # èƒŒæ™¯ãƒ»æ–‡è„ˆæƒ…å ±\n",
        "    \n",
        "    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–¢é€£\n",
        "    initial_prompt: str      # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "    current_prompt: str      # ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "    improved_prompt: str     # æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "    \n",
        "    # è©•ä¾¡çµæœ\n",
        "    quality_scores: Dict[str, float]  # å“è³ªã‚¹ã‚³ã‚¢\n",
        "    evaluation_feedback: str         # è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯\n",
        "    improvement_suggestions: List[str] # æ”¹å–„ææ¡ˆ\n",
        "    \n",
        "    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡\n",
        "    iteration_count: int        # æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«å›æ•°\n",
        "    max_iterations: int         # æœ€å¤§æ”¹å–„å›æ•°\n",
        "    is_satisfactory: bool       # å“è³ªåŸºæº–é”æˆãƒ•ãƒ©ã‚°\n",
        "    \n",
        "    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´\n",
        "    messages: Annotated[List[BaseMessage], add_messages]\n",
        "    \n",
        "    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\n",
        "    workflow_start_time: str\n",
        "    processing_logs: List[str]\n",
        "\n",
        "# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®š\n",
        "@dataclass\n",
        "class WorkflowConfig:\n",
        "    \"\"\"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®š\"\"\"\n",
        "    max_iterations: int = 3\n",
        "    quality_threshold: float = 8.0\n",
        "    temperature: float = 0.7\n",
        "    max_tokens: int = 4000\n",
        "    model_name: str = \"claude-3-5-sonnet-20241022\"  # ãƒ¢ãƒ‡ãƒ«åã‚’æ›´æ–°\n",
        "\n",
        "print(\"ğŸ”„ LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(\"\\n=== çŠ¶æ…‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ===\")\n",
        "print(\"ğŸ“ åŸºæœ¬æƒ…å ±: user_request, context\")\n",
        "print(\"ğŸ’­ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: initial_prompt, current_prompt, improved_prompt\")\n",
        "print(\"ğŸ“Š è©•ä¾¡: quality_scores, evaluation_feedback, improvement_suggestions\")\n",
        "print(\"âš™ï¸ åˆ¶å¾¡: iteration_count, max_iterations, is_satisfactory\")\n",
        "print(\"ğŸ“œ å±¥æ­´: messages, processing_logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "prompt-generator-agent",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®šç¾©ã—ã¾ã—ãŸ\n",
            "\n",
            "=== ä¸»è¦æ©Ÿèƒ½ ===\n",
            "ğŸ†• generate_initial_prompt: åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
            "ğŸ”„ improve_prompt: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„\n",
            "\n",
            "ğŸ’¡ Claude APIã‚’ä½¿ç”¨ã—ã¦é«˜å“è³ªãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™\n"
          ]
        }
      ],
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®šç¾©\n",
        "class PromptGeneratorAgent:\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\"\"\"\n",
        "    \n",
        "    def __init__(self, anthropic_client: anthropic.AsyncAnthropic, config: WorkflowConfig):\n",
        "        self.client = anthropic_client\n",
        "        self.config = config\n",
        "    \n",
        "    async def generate_initial_prompt(self, state: PromptWorkflowState) -> PromptWorkflowState:\n",
        "        \"\"\"åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ\"\"\"\n",
        "        try:\n",
        "            generation_prompt = f\"\"\"\n",
        "ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã€‘\n",
        "{state['user_request']}\n",
        "\n",
        "ã€æ–‡è„ˆæƒ…å ±ã€‘\n",
        "{state['context']}\n",
        "\n",
        "ã€ã‚¿ã‚¹ã‚¯ã€‘\n",
        "ä¸Šè¨˜ã®è¦æ±‚ã«åŸºã¥ã„ã¦ã€åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆåŸå‰‡ã€‘\n",
        "1. æ˜ç¢ºã§å…·ä½“çš„ãªæŒ‡ç¤º\n",
        "2. é©åˆ‡ãªæ–‡è„ˆã®æä¾›\n",
        "3. æœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼ã®å®šç¾©\n",
        "4. åˆ¶ç´„æ¡ä»¶ã®æ˜ç¤º\n",
        "5. å¿…è¦ã«å¿œã˜ã¦ä¾‹ç¤ºã‚’å«ã‚€\n",
        "\n",
        "ç”Ÿæˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚\n",
        "            \"\"\"\n",
        "            \n",
        "            response = await self.client.messages.create(\n",
        "                model=self.config.model_name,\n",
        "                max_tokens=self.config.max_tokens,\n",
        "                temperature=self.config.temperature,\n",
        "                messages=[{\"role\": \"user\", \"content\": generation_prompt}]\n",
        "            )\n",
        "            \n",
        "            generated_prompt = response.content[0].text.strip()\n",
        "            \n",
        "            # çŠ¶æ…‹æ›´æ–°\n",
        "            state['initial_prompt'] = generated_prompt\n",
        "            state['current_prompt'] = generated_prompt\n",
        "            state['processing_logs'].append(f\"âœ… åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(generated_prompt)}æ–‡å­—\")\n",
        "            \n",
        "            return state\n",
        "            \n",
        "        except Exception as e:\n",
        "            state['processing_logs'].append(f\"âŒ åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
        "            raise\n",
        "    \n",
        "    async def improve_prompt(self, state: PromptWorkflowState) -> PromptWorkflowState:\n",
        "        \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„\"\"\"\n",
        "        try:\n",
        "            improvement_prompt = f\"\"\"\n",
        "ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ã€ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘\n",
        "{state['current_prompt']}\n",
        "\n",
        "ã€è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€‘\n",
        "{state['evaluation_feedback']}\n",
        "\n",
        "ã€æ”¹å–„ææ¡ˆã€‘\n",
        "{chr(10).join(f'- {suggestion}' for suggestion in state['improvement_suggestions'])}\n",
        "\n",
        "ã€å“è³ªã‚¹ã‚³ã‚¢ã€‘\n",
        "{json.dumps(state['quality_scores'], indent=2, ensure_ascii=False)}\n",
        "\n",
        "ã€ã‚¿ã‚¹ã‚¯ã€‘\n",
        "ä¸Šè¨˜ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ææ¡ˆã«åŸºã¥ã„ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€æ”¹å–„è¦³ç‚¹ã€‘\n",
        "- ã‚ˆã‚Šæ˜ç¢ºã§å…·ä½“çš„ãªæŒ‡ç¤ºã«ä¿®æ­£\n",
        "- ä¸è¶³ã—ã¦ã„ã‚‹æ–‡è„ˆæƒ…å ±ã‚’è¿½åŠ \n",
        "- å‡ºåŠ›å½¢å¼ã‚’ã‚ˆã‚Šè©³ç´°ã«æŒ‡å®š\n",
        "- åˆ¶ç´„æ¡ä»¶ã®æ˜ç¢ºåŒ–\n",
        "- å¿…è¦ã«å¿œã˜ã¦ä¾‹ç¤ºã‚’è¿½åŠ \n",
        "\n",
        "æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚\n",
        "            \"\"\"\n",
        "            \n",
        "            response = await self.client.messages.create(\n",
        "                model=self.config.model_name,\n",
        "                max_tokens=self.config.max_tokens,\n",
        "                temperature=self.config.temperature,\n",
        "                messages=[{\"role\": \"user\", \"content\": improvement_prompt}]\n",
        "            )\n",
        "            \n",
        "            improved_prompt = response.content[0].text.strip()\n",
        "            \n",
        "            # çŠ¶æ…‹æ›´æ–°\n",
        "            state['improved_prompt'] = improved_prompt\n",
        "            state['current_prompt'] = improved_prompt\n",
        "            state['iteration_count'] += 1\n",
        "            state['processing_logs'].append(\n",
        "                f\"ğŸ”„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„å®Œäº† (ç¬¬{state['iteration_count']}å›): {len(improved_prompt)}æ–‡å­—\"\n",
        "            )\n",
        "            \n",
        "            return state\n",
        "            \n",
        "        except Exception as e:\n",
        "            state['processing_logs'].append(f\"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "print(\"ğŸ¤– ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(\"\\n=== ä¸»è¦æ©Ÿèƒ½ ===\")\n",
        "print(\"ğŸ†• generate_initial_prompt: åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\")\n",
        "print(\"ğŸ”„ improve_prompt: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„\")\n",
        "print(\"\\nğŸ’¡ Claude APIã‚’ä½¿ç”¨ã—ã¦é«˜å“è³ªãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "quality-evaluator-agent",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ å“è³ªè©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®šç¾©ã—ã¾ã—ãŸ\n",
            "\n",
            "=== è©•ä¾¡æ©Ÿèƒ½ ===\n",
            "ğŸ“Š evaluate_prompt_quality: 5é …ç›®ã§ã®å“è³ªè©•ä¾¡\n",
            "ğŸª è©•ä¾¡è¦³ç‚¹: æ˜ç¢ºæ€§ã€å…·ä½“æ€§ã€å®Œå…¨æ€§ã€åŠ¹ç‡æ€§ã€å†ç¾æ€§\n",
            "ğŸ¯ åŸºæº–å€¤é”æˆãƒã‚§ãƒƒã‚¯ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ\n"
          ]
        }
      ],
      "source": [
        "# å“è³ªè©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®šç¾©\n",
        "class QualityEvaluatorAgent:\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\"\"\"\n",
        "    \n",
        "    def __init__(self, anthropic_client: anthropic.AsyncAnthropic, config: WorkflowConfig):\n",
        "        self.client = anthropic_client\n",
        "        self.config = config\n",
        "    \n",
        "    async def evaluate_prompt_quality(self, state: PromptWorkflowState) -> PromptWorkflowState:\n",
        "        \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªã‚’è©•ä¾¡\"\"\"\n",
        "        try:\n",
        "            evaluation_prompt = f\"\"\"\n",
        "ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡ã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ã€è©•ä¾¡å¯¾è±¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘\n",
        "{state['current_prompt']}\n",
        "\n",
        "ã€å…ƒã®è¦æ±‚ã€‘\n",
        "{state['user_request']}\n",
        "\n",
        "ã€è©•ä¾¡åŸºæº–ã€‘\n",
        "ä»¥ä¸‹ã®5ã¤ã®è¦³ç‚¹ã‹ã‚‰1-10ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š\n",
        "\n",
        "1. **æ˜ç¢ºæ€§ (clarity)**: æŒ‡ç¤ºã®æ˜ç¢ºã•ã¨ç†è§£ã—ã‚„ã™ã•\n",
        "2. **å…·ä½“æ€§ (specificity)**: å…·ä½“çš„ãªè¦æ±‚ã®æ˜ç¤ºåº¦\n",
        "3. **å®Œå…¨æ€§ (completeness)**: å¿…è¦ãªæƒ…å ±ã®ç¶²ç¾…æ€§\n",
        "4. **åŠ¹ç‡æ€§ (efficiency)**: ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã¨ç°¡æ½”æ€§\n",
        "5. **å†ç¾æ€§ (reproducibility)**: ä¸€è²«ã—ãŸçµæœã®å†ç¾æ€§\n",
        "\n",
        "ã€å‡ºåŠ›å½¢å¼ã€‘\n",
        "ä»¥ä¸‹ã®JSONå½¢å¼ã§è©•ä¾¡çµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"scores\": {{\n",
        "    \"clarity\": 8.5,\n",
        "    \"specificity\": 7.0,\n",
        "    \"completeness\": 9.0,\n",
        "    \"efficiency\": 6.5,\n",
        "    \"reproducibility\": 8.0\n",
        "  }},\n",
        "  \"overall_score\": 7.8,\n",
        "  \"feedback\": \"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¼·ã¿ã¨å¼±ã¿ã®è©³ç´°ãªåˆ†æ\",\n",
        "  \"improvement_suggestions\": [\n",
        "    \"å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ1\",\n",
        "    \"å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ2\",\n",
        "    \"å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ3\"\n",
        "  ]\n",
        "}}\n",
        "```\n",
        "\n",
        "JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚ä»–ã®èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚\n",
        "            \"\"\"\n",
        "            \n",
        "            response = await self.client.messages.create(\n",
        "                model=self.config.model_name,\n",
        "                max_tokens=self.config.max_tokens,\n",
        "                temperature=0.3,  # è©•ä¾¡ã¯ä¸€è²«æ€§ã‚’é‡è¦–\n",
        "                messages=[{\"role\": \"user\", \"content\": evaluation_prompt}]\n",
        "            )\n",
        "            \n",
        "            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ\n",
        "            response_text = response.content[0].text.strip()\n",
        "            \n",
        "            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º\n",
        "            import re\n",
        "            json_match = re.search(r'```json\\s*({.*?})\\s*```', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_str = json_match.group(1)\n",
        "            else:\n",
        "                # JSONãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’JSONã¨ã—ã¦æ‰±ã†\n",
        "                json_str = response_text\n",
        "            \n",
        "            evaluation_result = json.loads(json_str)\n",
        "            \n",
        "            # çŠ¶æ…‹æ›´æ–°\n",
        "            state['quality_scores'] = evaluation_result['scores']\n",
        "            state['evaluation_feedback'] = evaluation_result['feedback']\n",
        "            state['improvement_suggestions'] = evaluation_result['improvement_suggestions']\n",
        "            \n",
        "            # å“è³ªåŸºæº–ã®ç¢ºèª\n",
        "            overall_score = evaluation_result['overall_score']\n",
        "            state['is_satisfactory'] = overall_score >= self.config.quality_threshold\n",
        "            \n",
        "            state['processing_logs'].append(\n",
        "                f\"ğŸ“Š å“è³ªè©•ä¾¡å®Œäº†: ç·åˆã‚¹ã‚³ã‚¢ {overall_score:.1f}/10 \"\n",
        "                f\"({'âœ… åŸºæº–é”æˆ' if state['is_satisfactory'] else 'âš ï¸ æ”¹å–„ãŒå¿…è¦'})\"\n",
        "            )\n",
        "            \n",
        "            return state\n",
        "            \n",
        "        except json.JSONDecodeError as e:\n",
        "            state['processing_logs'].append(f\"âŒ è©•ä¾¡çµæœJSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
        "            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©•ä¾¡å€¤ã‚’è¨­å®š\n",
        "            state['quality_scores'] = {\n",
        "                'clarity': 5.0, 'specificity': 5.0, 'completeness': 5.0,\n",
        "                'efficiency': 5.0, 'reproducibility': 5.0\n",
        "            }\n",
        "            state['evaluation_feedback'] = \"è©•ä¾¡çµæœã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ\"\n",
        "            state['improvement_suggestions'] = [\"è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèªãŒå¿…è¦\"]\n",
        "            state['is_satisfactory'] = False\n",
        "            return state\n",
        "            \n",
        "        except Exception as e:\n",
        "            state['processing_logs'].append(f\"âŒ å“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "print(\"ğŸ¯ å“è³ªè©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(\"\\n=== è©•ä¾¡æ©Ÿèƒ½ ===\")\n",
        "print(\"ğŸ“Š evaluate_prompt_quality: 5é …ç›®ã§ã®å“è³ªè©•ä¾¡\")\n",
        "print(\"ğŸª è©•ä¾¡è¦³ç‚¹: æ˜ç¢ºæ€§ã€å…·ä½“æ€§ã€å®Œå…¨æ€§ã€åŠ¹ç‡æ€§ã€å†ç¾æ€§\")\n",
        "print(\"ğŸ¯ åŸºæº–å€¤é”æˆãƒã‚§ãƒƒã‚¯ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "workflow-orchestrator",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¼ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’å®šç¾©ã—ã¾ã—ãŸ\n",
            "\n",
            "=== ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®š ===\n",
            "æœ€å¤§åå¾©å›æ•°: 3\n",
            "å“è³ªã—ãã„å€¤: 8.0/10\n",
            "ç”Ÿæˆæ¸©åº¦: 0.7\n",
            "ãƒ¢ãƒ‡ãƒ«: claude-3-5-sonnet-20241022\n",
            "\n",
            "=== å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ ===\n",
            "1ï¸âƒ£ åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
            "2ï¸âƒ£ å“è³ªè©•ä¾¡\n",
            "3ï¸âƒ£ æ”¹å–„è¦å¦åˆ¤å®š\n",
            "4ï¸âƒ£ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ (å¿…è¦ã«å¿œã˜ã¦ç¹°ã‚Šè¿”ã—)\n",
            "5ï¸âƒ£ æœ€çµ‚çµæœå‡ºåŠ›\n"
          ]
        }
      ],
      "source": [
        "# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼\n",
        "class PromptImprovementWorkflowOrchestrator:\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼\"\"\"\n",
        "    \n",
        "    def __init__(self, anthropic_client: anthropic.AsyncAnthropic, config: WorkflowConfig):\n",
        "        self.config = config\n",
        "        self.generator = PromptGeneratorAgent(anthropic_client, config)\n",
        "        self.evaluator = QualityEvaluatorAgent(anthropic_client, config)\n",
        "    \n",
        "    def create_initial_state(self, user_request: str, context: str = \"\") -> PromptWorkflowState:\n",
        "        \"\"\"åˆæœŸçŠ¶æ…‹ã‚’ä½œæˆ\"\"\"\n",
        "        return {\n",
        "            'user_request': user_request,\n",
        "            'context': context,\n",
        "            'initial_prompt': '',\n",
        "            'current_prompt': '',\n",
        "            'improved_prompt': '',\n",
        "            'quality_scores': {},\n",
        "            'evaluation_feedback': '',\n",
        "            'improvement_suggestions': [],\n",
        "            'iteration_count': 0,\n",
        "            'max_iterations': self.config.max_iterations,\n",
        "            'is_satisfactory': False,\n",
        "            'messages': [],\n",
        "            'workflow_start_time': datetime.now().isoformat(),\n",
        "            'processing_logs': []\n",
        "        }\n",
        "    \n",
        "    def should_continue_iteration(self, state: PromptWorkflowState) -> bool:\n",
        "        \"\"\"åå¾©ã‚’ç¶šè¡Œã™ã‚‹ã‹ã‚’åˆ¤æ–­\"\"\"\n",
        "        # å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚Œã°çµ‚äº†\n",
        "        if state['is_satisfactory']:\n",
        "            return False\n",
        "        \n",
        "        # æœ€å¤§åå¾©å›æ•°ã«é”ã—ã¦ã„ã‚Œã°çµ‚äº†\n",
        "        if state['iteration_count'] >= state['max_iterations']:\n",
        "            return False\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    async def run_workflow(self, user_request: str, context: str = \"\") -> PromptWorkflowState:\n",
        "        \"\"\"å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ\"\"\"\n",
        "        # åˆæœŸçŠ¶æ…‹ä½œæˆ\n",
        "        state = self.create_initial_state(user_request, context)\n",
        "        state['processing_logs'].append(f\"ğŸš€ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹: {state['workflow_start_time']}\")\n",
        "        \n",
        "        try:\n",
        "            # 1. åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
        "            state = await self.generator.generate_initial_prompt(state)\n",
        "            \n",
        "            # 2. åå¾©çš„æ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹\n",
        "            while True:\n",
        "                # å“è³ªè©•ä¾¡\n",
        "                state = await self.evaluator.evaluate_prompt_quality(state)\n",
        "                \n",
        "                # ç¶™ç¶šåˆ¤å®š\n",
        "                if not self.should_continue_iteration(state):\n",
        "                    break\n",
        "                \n",
        "                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„\n",
        "                state = await self.generator.improve_prompt(state)\n",
        "            \n",
        "            # å®Œäº†ãƒ­ã‚°\n",
        "            final_score = sum(state['quality_scores'].values()) / len(state['quality_scores'])\n",
        "            state['processing_logs'].append(\n",
        "                f\"ğŸ‰ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†: {state['iteration_count']}å›ã®æ”¹å–„, \"\n",
        "                f\"æœ€çµ‚ã‚¹ã‚³ã‚¢ {final_score:.1f}/10\"\n",
        "            )\n",
        "            \n",
        "            return state\n",
        "            \n",
        "        except Exception as e:\n",
        "            state['processing_logs'].append(f\"ğŸ’¥ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# ä½¿ç”¨ä¾‹ã®æº–å‚™\n",
        "workflow_config = WorkflowConfig(\n",
        "    max_iterations=3,\n",
        "    quality_threshold=8.0,\n",
        "    temperature=0.7,\n",
        "    model_name=\"claude-3-5-sonnet-20241022\"  # ãƒ¢ãƒ‡ãƒ«åã‚’æ›´æ–°\n",
        ")\n",
        "\n",
        "print(\"ğŸ¼ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\n",
        "print(\"\\n=== ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®š ===\")\n",
        "print(f\"æœ€å¤§åå¾©å›æ•°: {workflow_config.max_iterations}\")\n",
        "print(f\"å“è³ªã—ãã„å€¤: {workflow_config.quality_threshold}/10\")\n",
        "print(f\"ç”Ÿæˆæ¸©åº¦: {workflow_config.temperature}\")\n",
        "print(f\"ãƒ¢ãƒ‡ãƒ«: {workflow_config.model_name}\")\n",
        "\n",
        "print(\"\\n=== å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ ===\")\n",
        "print(\"1ï¸âƒ£ åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\")\n",
        "print(\"2ï¸âƒ£ å“è³ªè©•ä¾¡\")\n",
        "print(\"3ï¸âƒ£ æ”¹å–„è¦å¦åˆ¤å®š\")\n",
        "print(\"4ï¸âƒ£ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ (å¿…è¦ã«å¿œã˜ã¦ç¹°ã‚Šè¿”ã—)\")\n",
        "print(\"5ï¸âƒ£ æœ€çµ‚çµæœå‡ºåŠ›\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "langgraph-implementation",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ•¸ï¸ LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè£…ã—ã¾ã—ãŸ\n",
            "\n",
            "ğŸ”„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•\n",
            "\n",
            "    START\n",
            "      â†“\n",
            "  [Generate]  â† â”€â”€â”€â”\n",
            "      â†“           â”‚\n",
            "  [Evaluate]      â”‚\n",
            "      â†“           â”‚\n",
            "   Decision       â”‚\n",
            "   â†™     â†˜        â”‚\n",
            "Continue   End     â”‚\n",
            "   â†“       â†“       â”‚\n",
            "   â””â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n",
            "           â†“\n",
            "       [Finalize]\n",
            "           â†“\n",
            "         FINISH\n",
            "\n",
            "ğŸ“ ãƒãƒ¼ãƒ‰èª¬æ˜:\n",
            "â€¢ Generate: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ/æ”¹å–„\n",
            "â€¢ Evaluate: å“è³ªè©•ä¾¡ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯\n",
            "â€¢ Decision: ç¶™ç¶š/çµ‚äº†åˆ¤å®š\n",
            "â€¢ Finalize: çµæœã®æœ€çµ‚åŒ–\n",
            "    \n",
            "âœ… LangGraphã®åˆæœŸåŒ–å®Œäº†\n",
            "ğŸ“Š ãƒãƒ¼ãƒ‰æ•°: 3å€‹ (generate, evaluate, finalize)\n",
            "ğŸ”— ã‚¨ãƒƒã‚¸: æ¡ä»¶åˆ†å²ã‚’å«ã‚€å‹•çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Safe API key handling\n",
        "import os\n",
        "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"âš ï¸ ANTHROPIC_API_KEY not set. Some features may not work.\")\n",
        "    # Continue with limited functionality\n",
        "\n",
        "# LangGraphã«ã‚ˆã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè£…\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "def create_prompt_improvement_graph(anthropic_client: anthropic.AsyncAnthropic, \n",
        "                                   config: WorkflowConfig) -> StateGraph:\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ç”¨ã®StateGraphã‚’ä½œæˆ\"\"\"\n",
        "    \n",
        "    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ\n",
        "    generator = PromptGeneratorAgent(anthropic_client, config)\n",
        "    evaluator = QualityEvaluatorAgent(anthropic_client, config)\n",
        "    \n",
        "    # ãƒãƒ¼ãƒ‰é–¢æ•°ã®å®šç¾©\n",
        "    async def generate_node(state: PromptWorkflowState) -> PromptWorkflowState:\n",
        "        \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒãƒ¼ãƒ‰\"\"\"\n",
        "        if state['iteration_count'] == 0:\n",
        "            # åˆå›ã¯åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
        "            return await generator.generate_initial_prompt(state)\n",
        "        else:\n",
        "            # 2å›ç›®ä»¥é™ã¯æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
        "            return await generator.improve_prompt(state)\n",
        "    \n",
        "    async def evaluate_node(state: PromptWorkflowState) -> PromptWorkflowState:\n",
        "        \"\"\"å“è³ªè©•ä¾¡ãƒãƒ¼ãƒ‰\"\"\"\n",
        "        return await evaluator.evaluate_prompt_quality(state)\n",
        "    \n",
        "    def should_continue(state: PromptWorkflowState) -> str:\n",
        "        \"\"\"ç¶™ç¶šåˆ¤å®šé–¢æ•°\"\"\"\n",
        "        # å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚Œã°çµ‚äº†\n",
        "        if state['is_satisfactory']:\n",
        "            return \"end\"\n",
        "        \n",
        "        # æœ€å¤§åå¾©å›æ•°ã«é”ã—ã¦ã„ã‚Œã°çµ‚äº†\n",
        "        if state['iteration_count'] >= state['max_iterations']:\n",
        "            return \"end\"\n",
        "        \n",
        "        return \"generate\"\n",
        "    \n",
        "    def finalize_node(state: PromptWorkflowState) -> PromptWorkflowState:\n",
        "        \"\"\"æœ€çµ‚åŒ–ãƒãƒ¼ãƒ‰\"\"\"\n",
        "        final_score = sum(state['quality_scores'].values()) / len(state['quality_scores']) if state['quality_scores'] else 0\n",
        "        state['processing_logs'].append(\n",
        "            f\"âœ¨ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æœ€çµ‚åŒ–: {state['iteration_count']}å›ã®æ”¹å–„, \"\n",
        "            f\"æœ€çµ‚ã‚¹ã‚³ã‚¢ {final_score:.1f}/10\"\n",
        "        )\n",
        "        return state\n",
        "    \n",
        "    # ã‚°ãƒ©ãƒ•æ§‹ç¯‰\n",
        "    graph = StateGraph(PromptWorkflowState)\n",
        "    \n",
        "    # ãƒãƒ¼ãƒ‰è¿½åŠ \n",
        "    graph.add_node(\"generate\", generate_node)\n",
        "    graph.add_node(\"evaluate\", evaluate_node)\n",
        "    graph.add_node(\"finalize\", finalize_node)\n",
        "    \n",
        "    # ã‚¨ãƒƒã‚¸è¨­å®š\n",
        "    graph.set_entry_point(\"generate\")\n",
        "    graph.add_edge(\"generate\", \"evaluate\")\n",
        "    graph.add_conditional_edges(\n",
        "        \"evaluate\",\n",
        "        should_continue,\n",
        "        {\n",
        "            \"generate\": \"generate\",\n",
        "            \"end\": \"finalize\"\n",
        "        }\n",
        "    )\n",
        "    graph.set_finish_point(\"finalize\")\n",
        "    \n",
        "    return graph\n",
        "\n",
        "# ã‚°ãƒ©ãƒ•ã®å¯è¦–åŒ–æƒ…å ±ã‚’ç”Ÿæˆ\n",
        "def get_workflow_visualization() -> str:\n",
        "    \"\"\"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ–æƒ…å ±ã‚’å–å¾—\"\"\"\n",
        "    return \"\"\"\n",
        "ğŸ”„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•\n",
        "\n",
        "    START\n",
        "      â†“\n",
        "  [Generate]  â† â”€â”€â”€â”\n",
        "      â†“           â”‚\n",
        "  [Evaluate]      â”‚\n",
        "      â†“           â”‚\n",
        "   Decision       â”‚\n",
        "   â†™     â†˜        â”‚\n",
        "Continue   End     â”‚\n",
        "   â†“       â†“       â”‚\n",
        "   â””â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n",
        "           â†“\n",
        "       [Finalize]\n",
        "           â†“\n",
        "         FINISH\n",
        "\n",
        "ğŸ“ ãƒãƒ¼ãƒ‰èª¬æ˜:\n",
        "â€¢ Generate: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ/æ”¹å–„\n",
        "â€¢ Evaluate: å“è³ªè©•ä¾¡ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯\n",
        "â€¢ Decision: ç¶™ç¶š/çµ‚äº†åˆ¤å®š\n",
        "â€¢ Finalize: çµæœã®æœ€çµ‚åŒ–\n",
        "    \"\"\"\n",
        "\n",
        "print(\"ğŸ•¸ï¸ LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè£…ã—ã¾ã—ãŸ\")\n",
        "print(get_workflow_visualization())\n",
        "\n",
        "# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ\n",
        "if os.getenv('ANTHROPIC_API_KEY'):\n",
        "    try:\n",
        "        # ãƒ†ã‚¹ãƒˆç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ\n",
        "        test_client = anthropic.AsyncAnthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
        "        \n",
        "        # ã‚°ãƒ©ãƒ•ä½œæˆ\n",
        "        prompt_graph = create_prompt_improvement_graph(test_client, workflow_config)\n",
        "        \n",
        "        print(\"âœ… LangGraphã®åˆæœŸåŒ–å®Œäº†\")\n",
        "        print(f\"ğŸ“Š ãƒãƒ¼ãƒ‰æ•°: 3å€‹ (generate, evaluate, finalize)\")\n",
        "        print(f\"ğŸ”— ã‚¨ãƒƒã‚¸: æ¡ä»¶åˆ†å²ã‚’å«ã‚€å‹•çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ LangGraphåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        prompt_graph = None\n",
        "else:\n",
        "    print(\"âš ï¸ ANTHROPIC_API_KEYãŒæœªè¨­å®šã®ãŸã‚ã€ã‚°ãƒ©ãƒ•ã¯å¾Œã§åˆæœŸåŒ–ã•ã‚Œã¾ã™\")\n",
        "    prompt_graph = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "workflow-execution-demo",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ­ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒ‡ãƒ¢ã‚’æº–å‚™ã—ã¾ã—ãŸ\n",
            "\n",
            "ğŸ’¡ å®Ÿè¡Œæ–¹æ³•:\n",
            "  result = await demo_workflow_execution()\n",
            "\n",
            "âš ï¸ æ³¨æ„: APIå‘¼ã³å‡ºã—ãŒç™ºç”Ÿã™ã‚‹ãŸã‚ã€å®Ÿè¡Œå‰ã«APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n",
            "\n",
            "ğŸ”„ ç°¡å˜ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...\n",
            "âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æº–å‚™å®Œäº† - ä¸Šè¨˜ã®demo_workflow_execution()ã‚’å®Ÿè¡Œã—ã¦ãƒ†ã‚¹ãƒˆã§ãã¾ã™\n"
          ]
        }
      ],
      "source": [
        "# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒ‡ãƒ¢\n",
        "async def demo_workflow_execution():\n",
        "    \"\"\"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\"\"\"\n",
        "    \n",
        "    if not os.getenv('ANTHROPIC_API_KEY'):\n",
        "        print(\"âš ï¸ ãƒ‡ãƒ¢å®Ÿè¡Œã«ã¯ANTHROPIC_API_KEYãŒå¿…è¦ã§ã™\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ\n",
        "        client = anthropic.AsyncAnthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
        "        \n",
        "        # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ä½œæˆ\n",
        "        orchestrator = PromptImprovementWorkflowOrchestrator(client, workflow_config)\n",
        "        \n",
        "        # ãƒ†ã‚¹ãƒˆç”¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆ\n",
        "        test_request = \"ECã‚µã‚¤ãƒˆã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã€å£²ä¸Šå‘ä¸Šã®ãŸã‚ã®ææ¡ˆã‚’ã—ã¦ã»ã—ã„\"\n",
        "        test_context = \"ãƒ‡ãƒ¼ã‚¿ã«ã¯æœˆåˆ¥å£²ä¸Šã€ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å±æ€§ãŒå«ã¾ã‚Œã¦ã„ã¾ã™\"\n",
        "        \n",
        "        print(\"ğŸ¬ ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹\")\n",
        "        print(f\"ğŸ“ è¦æ±‚: {test_request}\")\n",
        "        print(f\"ğŸ“„ æ–‡è„ˆ: {test_context}\")\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        \n",
        "        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ\n",
        "        result = await orchestrator.run_workflow(test_request, test_context)\n",
        "        \n",
        "        # çµæœè¡¨ç¤º\n",
        "        print(\"\\nğŸ¯ å®Ÿè¡Œçµæœ\")\n",
        "        print(\"\\nğŸ“Š å“è³ªã‚¹ã‚³ã‚¢:\")\n",
        "        for metric, score in result['quality_scores'].items():\n",
        "            print(f\"  {metric}: {score:.1f}/10\")\n",
        "        \n",
        "        final_score = sum(result['quality_scores'].values()) / len(result['quality_scores'])\n",
        "        print(f\"\\nğŸª ç·åˆã‚¹ã‚³ã‚¢: {final_score:.1f}/10\")\n",
        "        print(f\"âœ… å“è³ªåŸºæº–é”æˆ: {'ã¯ã„' if result['is_satisfactory'] else 'ã„ã„ãˆ'}\")\n",
        "        print(f\"ğŸ”„ æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«æ•°: {result['iteration_count']}å›\")\n",
        "        \n",
        "        print(\"\\nğŸ“œ å‡¦ç†ãƒ­ã‚°:\")\n",
        "        for log in result['processing_logs']:\n",
        "            print(f\"  {log}\")\n",
        "        \n",
        "        print(\"\\nğŸ’­ æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\")\n",
        "        print(\"â”€\" * 50)\n",
        "        print(result['current_prompt'])\n",
        "        print(\"â”€\" * 50)\n",
        "        \n",
        "        if result['improvement_suggestions']:\n",
        "            print(\"\\nğŸ’¡ æ”¹å–„ææ¡ˆ:\")\n",
        "            for i, suggestion in enumerate(result['improvement_suggestions'], 1):\n",
        "                print(f\"  {i}. {suggestion}\")\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ãƒ‡ãƒ¢å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"ğŸ­ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒ‡ãƒ¢ã‚’æº–å‚™ã—ã¾ã—ãŸ\")\n",
        "print(\"\\nğŸ’¡ å®Ÿè¡Œæ–¹æ³•:\")\n",
        "print(\"  result = await demo_workflow_execution()\")\n",
        "print(\"\\nâš ï¸ æ³¨æ„: APIå‘¼ã³å‡ºã—ãŒç™ºç”Ÿã™ã‚‹ãŸã‚ã€å®Ÿè¡Œå‰ã«APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n",
        "\n",
        "# APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ç°¡å˜ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ\n",
        "if os.getenv('ANTHROPIC_API_KEY') and api_test_result:\n",
        "    print(\"\\nğŸ”„ ç°¡å˜ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...\")\n",
        "    # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆ¤æ–­ã«å§”ã­ã‚‹\n",
        "    print(\"âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æº–å‚™å®Œäº† - ä¸Šè¨˜ã®demo_workflow_execution()ã‚’å®Ÿè¡Œã—ã¦ãƒ†ã‚¹ãƒˆã§ãã¾ã™\")\n",
        "else:\n",
        "    print(\"âš ï¸ APIã‚­ãƒ¼æœªè¨­å®šã¾ãŸã¯ãƒ†ã‚¹ãƒˆå¤±æ•—ã®ãŸã‚ã€å®Ÿéš›ã®å®Ÿè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-5-prompt-engine",
      "metadata": {},
      "source": [
        "# 5. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-code-input",
      "metadata": {},
      "source": [
        "# ğŸ’» ã‚³ãƒ¼ãƒ‰å…¥åŠ›ãƒ»è§£æã‚»ã‚¯ã‚·ãƒ§ãƒ³ (v1.1.0 æ–°æ©Ÿèƒ½)\n",
        "\n",
        "AIãŒç”Ÿæˆã—ãŸPoCãƒ‡ãƒ¢ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ãƒ»ç·¨é›†ã—ã€ãã®ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "id": "import-code-modules",
      "metadata": {},
      "source": [
        "\n",
        "# Fallback for interactive widgets\n",
        "try:\n",
        "    from IPython.display import display, HTML\n",
        "    import ipywidgets as widgets\n",
        "    INTERACTIVE_MODE = True\n",
        "except ImportError:\n",
        "    # Mock implementations for testing\n",
        "    def display(*args, **kwargs):\n",
        "        for arg in args:\n",
        "            print(f\"[DISPLAY] {arg}\")\n",
        "    \n",
        "    def HTML(content):\n",
        "        return f\"[HTML] {content}\"\n",
        "    \n",
        "    class MockWidget:\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            pass\n",
        "    \n",
        "    # Mock common widgets\n",
        "    widgets = type('widgets', (), {\n",
        "        'Text': MockWidget,\n",
        "        'Button': MockWidget,\n",
        "        'VBox': MockWidget,\n",
        "        'HBox': MockWidget,\n",
        "        'Output': MockWidget,\n",
        "        'interactive_output': lambda *args, **kwargs: None\n",
        "    })()\n",
        "    \n",
        "    INTERACTIVE_MODE = False\n",
        "\n",
        "# ã‚³ãƒ¼ãƒ‰å…¥åŠ›ãƒ»è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from src.code_input_handler import CodeInputHandler, CodeInput\n",
        "from src.code_analyzer import CodeAnalyzer\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¨ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–\n",
        "code_handler = CodeInputHandler()\n",
        "code_analyzer = CodeAnalyzer()\n",
        "\n",
        "print(\"âœ… ã‚³ãƒ¼ãƒ‰å…¥åŠ›ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "create-code-input-ui",
      "metadata": {},
      "source": [
        "\n",
        "# Fallback for interactive widgets\n",
        "try:\n",
        "    from IPython.display import display, HTML\n",
        "    import ipywidgets as widgets\n",
        "    INTERACTIVE_MODE = True\n",
        "except ImportError:\n",
        "    # Mock implementations for testing\n",
        "    def display(*args, **kwargs):\n",
        "        for arg in args:\n",
        "            print(f\"[DISPLAY] {arg}\")\n",
        "    \n",
        "    def HTML(content):\n",
        "        return f\"[HTML] {content}\"\n",
        "    \n",
        "    class MockWidget:\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            pass\n",
        "    \n",
        "    # Mock common widgets\n",
        "    widgets = type('widgets', (), {\n",
        "        'Text': MockWidget,\n",
        "        'Button': MockWidget,\n",
        "        'VBox': MockWidget,\n",
        "        'HBox': MockWidget,\n",
        "        'Output': MockWidget,\n",
        "        'interactive_output': lambda *args, **kwargs: None\n",
        "    })()\n",
        "    \n",
        "    INTERACTIVE_MODE = False\n",
        "\n",
        "# ã‚³ãƒ¼ãƒ‰å…¥åŠ›UIã®ä½œæˆ\n",
        "\n",
        "# UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ\n",
        "code_title = widgets.Text(\n",
        "    placeholder='ä¾‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ',\n",
        "    description='ã‚¿ã‚¤ãƒˆãƒ«:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "code_language = widgets.Dropdown(\n",
        "    options=['python', 'javascript', 'typescript', 'java', 'go', 'rust', 'auto'],\n",
        "    value='auto',\n",
        "    description='è¨€èª:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "code_description = widgets.Textarea(\n",
        "    placeholder='ã“ã®ã‚³ãƒ¼ãƒ‰ã®ç›®çš„ã‚„æ©Ÿèƒ½ã‚’èª¬æ˜ã—ã¦ãã ã•ã„',\n",
        "    description='èª¬æ˜:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout={'width': '100%', 'height': '80px'}\n",
        ")\n",
        "\n",
        "code_input = widgets.Textarea(\n",
        "    placeholder='# AIãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„\\n\\ndef main():\\n    pass',\n",
        "    description='ã‚³ãƒ¼ãƒ‰:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout={'width': '100%', 'height': '400px'}\n",
        ")\n",
        "\n",
        "requirements_input = widgets.Textarea(\n",
        "    placeholder='ä¾‹: ã‚»ã‚­ãƒ¥ã‚¢ãªèªè¨¼ã€é«˜é€Ÿå‡¦ç†ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°',\n",
        "    description='è¦ä»¶:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout={'width': '100%', 'height': '80px'}\n",
        ")\n",
        "\n",
        "analyze_button = widgets.Button(\n",
        "    description='ã‚³ãƒ¼ãƒ‰è§£æå®Ÿè¡Œ',\n",
        "    button_style='primary',\n",
        "    icon='search'\n",
        ")\n",
        "\n",
        "generate_prompt_button = widgets.Button(\n",
        "    description='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ',\n",
        "    button_style='success',\n",
        "    icon='magic'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\n",
        "form_items = [\n",
        "    widgets.HTML('<h3>ğŸ“ ã‚³ãƒ¼ãƒ‰æƒ…å ±å…¥åŠ›</h3>'),\n",
        "    code_title,\n",
        "    code_language,\n",
        "    code_description,\n",
        "    requirements_input,\n",
        "    widgets.HTML('<h3>ğŸ’» ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰</h3>'),\n",
        "    code_input,\n",
        "    widgets.HBox([analyze_button, generate_prompt_button]),\n",
        "    output_area\n",
        "]\n",
        "\n",
        "form = widgets.VBox(form_items, layout={'width': '100%'})\n",
        "display(form)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "code-analysis-handlers",
      "metadata": {},
      "source": [
        "# ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®å®šç¾©\n",
        "\n",
        "def on_analyze_click(b):\n",
        "    \"\"\"ã‚³ãƒ¼ãƒ‰è§£æãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼\"\"\"\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        \n",
        "        if not code_input.value.strip():\n",
        "            print(\"âš ï¸ ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\")\n",
        "            return\n",
        "        \n",
        "        print(\"ğŸ” ã‚³ãƒ¼ãƒ‰è§£æä¸­...\")\n",
        "        \n",
        "        # ã‚³ãƒ¼ãƒ‰å…¥åŠ›ã‚’å‡¦ç†\n",
        "        language = None if code_language.value == 'auto' else code_language.value\n",
        "        \n",
        "        code_data, analysis = code_handler.process_code_input(\n",
        "            code=code_input.value,\n",
        "            language=language,\n",
        "            title=code_title.value,\n",
        "            description=code_description.value,\n",
        "            requirements=requirements_input.value\n",
        "        )\n",
        "        \n",
        "        # è§£æçµæœè¡¨ç¤º\n",
        "        print(\"\\nâœ… è§£æå®Œäº†!\\n\")\n",
        "        print(f\"ğŸ”¤ è¨€èª: {analysis.language}\")\n",
        "        print(f\"ğŸ“Š ã‚³ãƒ¼ãƒ‰è¡Œæ•°: {analysis.lines_of_code}\")\n",
        "        print(f\"ğŸ¯ ä¸»è¦ç›®çš„: {analysis.main_purpose}\")\n",
        "        print(f\"âš™ï¸ è¤‡é›‘åº¦: {analysis.complexity_estimate}\")\n",
        "        \n",
        "        if analysis.functions:\n",
        "            print(f\"\\nğŸ“¦ é–¢æ•° ({len(analysis.functions)}):\")\n",
        "            for func in analysis.functions[:5]:\n",
        "                print(f\"  - {func}\")\n",
        "        \n",
        "        if analysis.classes:\n",
        "            print(f\"\\nğŸ—ï¸ ã‚¯ãƒ©ã‚¹ ({len(analysis.classes)}):\")\n",
        "            for cls in analysis.classes[:5]:\n",
        "                print(f\"  - {cls}\")\n",
        "        \n",
        "        if analysis.suggested_improvements:\n",
        "            print(f\"\\nğŸ’¡ æ”¹å–„ææ¡ˆ:\")\n",
        "            for suggestion in analysis.suggested_improvements:\n",
        "                print(f\"  â€¢ {suggestion}\")\n",
        "        \n",
        "        # è©³ç´°è§£æï¼ˆPython ã®å ´åˆï¼‰\n",
        "        if analysis.language == 'python':\n",
        "            detailed = code_analyzer.analyze_python_ast(code_input.value)\n",
        "            if 'functions' in detailed:\n",
        "                print(f\"\\nğŸ“ˆ è©³ç´°è§£æ:\")\n",
        "                for func in detailed['functions'][:3]:\n",
        "                    print(f\"  é–¢æ•° {func['name']}: è¤‡é›‘åº¦ {func['complexity']}\")\n",
        "\n",
        "def on_generate_prompt_click(b):\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼\"\"\"\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        \n",
        "        if not code_input.value.strip():\n",
        "            print(\"âš ï¸ ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\")\n",
        "            return\n",
        "        \n",
        "        print(\"ğŸ¯ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\")\n",
        "        \n",
        "        # ã¾ãšã‚³ãƒ¼ãƒ‰è§£æ\n",
        "        language = None if code_language.value == 'auto' else code_language.value\n",
        "        code_data, analysis = code_handler.process_code_input(\n",
        "            code=code_input.value,\n",
        "            language=language,\n",
        "            title=code_title.value,\n",
        "            description=code_description.value,\n",
        "            requirements=requirements_input.value\n",
        "        )\n",
        "        \n",
        "        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ\n",
        "        context = code_handler.generate_prompt_context()\n",
        "        \n",
        "        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆå®Ÿéš›ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨é€£æºï¼‰\n",
        "        from src.generator import PromptGenerator\n",
        "        generator = PromptGenerator()\n",
        "        \n",
        "        # ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
        "        prompt_template = f\"\"\"\n",
        "ã‚ãªãŸã¯{context['language']}ã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’æ”¹å–„ãƒ»æ‹¡å¼µã—ã¦ãã ã•ã„ï¼š\n",
        "\n",
        "ã€ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã€‘\n",
        "```{context['language']}\n",
        "{context['code_snippet']}\n",
        "```\n",
        "\n",
        "ã€ã‚³ãƒ¼ãƒ‰ã®ç›®çš„ã€‘\n",
        "{context['main_purpose']}\n",
        "\n",
        "ã€è¦ä»¶ã€‘\n",
        "{context.get('requirements', 'ãªã—')}\n",
        "\n",
        "ã€æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã€‘\n",
        "{chr(10).join('- ' + s for s in context['suggestions'][:3])}\n",
        "\n",
        "ã€æœŸå¾…ã™ã‚‹å‡ºåŠ›ã€‘\n",
        "1. æ”¹å–„ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰\n",
        "2. å¤‰æ›´å†…å®¹ã®èª¬æ˜\n",
        "3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚„å“è³ªã®å‘ä¸Šç‚¹\n",
        "\"\"\"\n",
        "        \n",
        "        print(\"\\nâœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†!\\n\")\n",
        "        print(\"ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(prompt_template)\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # å±¥æ­´ã«ä¿å­˜\n",
        "        if 'history_manager' in globals():\n",
        "            prompt_id = history_manager.save_prompt(\n",
        "                prompt_type='code_based',\n",
        "                user_requirements=context.get('requirements', ''),\n",
        "                generated_prompt=prompt_template,\n",
        "                metadata={\n",
        "                    'language': context['language'],\n",
        "                    'lines_of_code': context['lines_of_code'],\n",
        "                    'complexity': context['complexity']\n",
        "                }\n",
        "            )\n",
        "            print(f\"\\nğŸ’¾ å±¥æ­´ã«ä¿å­˜ã—ã¾ã—ãŸ (ID: {prompt_id})\")\n",
        "\n",
        "# ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’æ¥ç¶š\n",
        "analyze_button.on_click(on_analyze_click)\n",
        "generate_prompt_button.on_click(on_generate_prompt_click)\n",
        "\n",
        "print(\"âœ… ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®šå®Œäº†\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "code-input-example",
      "metadata": {},
      "source": [
        "# ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã§ãƒ‡ãƒ¢å®Ÿè¡Œ\n",
        "sample_code = '''\n",
        "def fibonacci(n):\n",
        "    \"\"\"ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã®nç•ªç›®ã®å€¤ã‚’è¿”ã™\"\"\"\n",
        "    if n <= 0:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "def main():\n",
        "    # ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã®æœ€åˆã®10å€‹ã‚’è¡¨ç¤º\n",
        "    for i in range(10):\n",
        "        print(f\"F({i}) = {fibonacci(i)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# ã‚µãƒ³ãƒ—ãƒ«ã‚’UIã«è¨­å®š\n",
        "code_title.value = \"ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ç”Ÿæˆå™¨\"\n",
        "code_language.value = \"python\"\n",
        "code_description.value = \"å†å¸°çš„ã«ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã‚’è¨ˆç®—ã™ã‚‹Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒ \"\n",
        "code_input.value = sample_code\n",
        "requirements_input.value = \"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ”¹å–„ã€ãƒ¡ãƒ¢åŒ–ã®å®Ÿè£…ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°\"\n",
        "\n",
        "print(\"ğŸ“Œ ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¾ã—ãŸã€‚'ã‚³ãƒ¼ãƒ‰è§£æå®Ÿè¡Œ'ã¾ãŸã¯'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ'ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "code-metrics-viz",
      "metadata": {},
      "source": [
        "### ğŸ“Š ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¯è¦–åŒ–"
      ]
    },
    {
      "cell_type": "code",
      "id": "visualize-code-metrics",
      "metadata": {},
      "source": [
        "# ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¯è¦–åŒ–\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "def visualize_code_metrics(code: str, language: str = 'python'):\n",
        "    \"\"\"ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å¯è¦–åŒ–\"\"\"\n",
        "    \n",
        "    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—\n",
        "    metrics = code_analyzer.calculate_metrics(code, language)\n",
        "    \n",
        "    # ã‚°ãƒ©ãƒ•ä½œæˆ\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    \n",
        "    # 1. ä¿å®ˆæ€§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n",
        "    ax1 = axes[0]\n",
        "    maintainability = metrics.maintainability_index\n",
        "    color = 'green' if maintainability > 70 else 'orange' if maintainability > 40 else 'red'\n",
        "    ax1.bar(['ä¿å®ˆæ€§'], [maintainability], color=color)\n",
        "    ax1.set_ylim(0, 100)\n",
        "    ax1.set_ylabel('ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')\n",
        "    ax1.set_title('ä¿å®ˆæ€§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹')\n",
        "    ax1.text(0, maintainability + 2, f'{maintainability:.1f}', ha='center')\n",
        "    \n",
        "    # 2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç‡ã¨ãƒ†ã‚¹ãƒˆç‡\n",
        "    ax2 = axes[1]\n",
        "    categories = ['ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ', 'ãƒ†ã‚¹ãƒˆ']\n",
        "    values = [metrics.documentation_ratio * 100, metrics.test_ratio * 100]\n",
        "    colors = ['blue', 'purple']\n",
        "    ax2.bar(categories, values, color=colors)\n",
        "    ax2.set_ylim(0, 100)\n",
        "    ax2.set_ylabel('ã‚«ãƒãƒ¬ãƒƒã‚¸ (%)')\n",
        "    ax2.set_title('ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸')\n",
        "    \n",
        "    # 3. è¤‡é›‘åº¦\n",
        "    ax3 = axes[2]\n",
        "    complexity_data = {\n",
        "        'å¾ªç’°çš„': metrics.cyclomatic_complexity,\n",
        "        'èªçŸ¥çš„': metrics.cognitive_complexity\n",
        "    }\n",
        "    ax3.bar(complexity_data.keys(), complexity_data.values(), color='coral')\n",
        "    ax3.set_ylabel('è¤‡é›‘åº¦')\n",
        "    ax3.set_title('ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º\n",
        "if code_input.value:\n",
        "    print(\"ğŸ“Š ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ\")\n",
        "    metrics = visualize_code_metrics(code_input.value, 'python')\n",
        "    print(f\"\\nè©³ç´°:\")\n",
        "    print(f\"- å¾ªç’°çš„è¤‡é›‘åº¦: {metrics.cyclomatic_complexity}\")\n",
        "    print(f\"- èªçŸ¥çš„è¤‡é›‘åº¦: {metrics.cognitive_complexity:.1f}\")\n",
        "    print(f\"- ä¿å®ˆæ€§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {metrics.maintainability_index:.1f}/100\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "6lxwss85u0t",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†\n",
            "  - Generator: claude-3-5-sonnet-20241022\n",
            "  - Evaluator: claude-3-5-sonnet-20241022\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Safe API key handling\n",
        "import os\n",
        "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"âš ï¸ ANTHROPIC_API_KEY not set. Some features may not work.\")\n",
        "    # Continue with limited functionality\n",
        "\n",
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨åˆæœŸåŒ–\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('.')  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
        "\n",
        "# æ—¢å­˜ã®src/generator.pyã¨src/evaluator.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "from src.generator import PromptGenerator\n",
        "from src.evaluator import PromptEvaluator\n",
        "\n",
        "# Anthropicã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰\n",
        "generator = None\n",
        "evaluator = None\n",
        "\n",
        "if os.getenv('ANTHROPIC_API_KEY') and os.getenv('ANTHROPIC_API_KEY') != 'your_anthropic_api_key_here':\n",
        "    try:\n",
        "        # PromptGeneratorã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ\n",
        "        generator = PromptGenerator(model=\"claude-3-5-sonnet-20241022\")\n",
        "        evaluator = PromptEvaluator(model=\"claude-3-5-sonnet-20241022\")\n",
        "        print(\"âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†\")\n",
        "        print(f\"  - Generator: {generator.model}\")\n",
        "        print(f\"  - Evaluator: {evaluator.model}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "orgb50ulhmb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...\n",
            "\n",
            "=== ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…å®¹ ===\n",
            "ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: data_analysis\n",
            "è¦æ±‚: ECã‚µã‚¤ãƒˆã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­£ç¯€æ€§ã‚’åˆ†æã—ã€å£²ä¸Šå‘ä¸Šæ–½ç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„\n",
            "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {'data_description': 'æœˆåˆ¥å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆéå»2å¹´åˆ†ï¼‰', 'available_data': 'å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šã€é¡§å®¢å±æ€§ãƒ‡ãƒ¼ã‚¿', 'analysis_objective': 'å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®šã¨å£²ä¸Šå‘ä¸Š'}\n",
            "åˆ¶ç´„: çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼ã—ã€å®Ÿè£…å¯èƒ½ãªå…·ä½“çš„æ–½ç­–ã‚’ææ¡ˆã™ã‚‹ã“ã¨\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:13:10,123 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ç”Ÿæˆçµæœ ===\n",
            "âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”ŸæˆæˆåŠŸ\n",
            "é•·ã•: 756æ–‡å­—\n",
            "\n",
            "=== ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ===\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼š\n",
            "\n",
            "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆãŠã‚ˆã³ECãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã¨ã—ã¦ã€ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š\n",
            "\n",
            "ã‚¿ã‚¹ã‚¯ï¼š\n",
            "æä¾›ã•ã‚ŒãŸECã‚µã‚¤ãƒˆã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š\n",
            "\n",
            "1. å­£ç¯€æ€§åˆ†æ\n",
            "- æœˆåˆ¥å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ã®çµ±è¨ˆçš„åˆ†æï¼ˆè‡ªå·±ç›¸é–¢åˆ†æã€æ™‚ç³»åˆ—åˆ†è§£ï¼‰\n",
            "- ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å­£ç¯€å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š\n",
            "- é¡§å®¢å±æ€§ã¨è³¼è²·ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç›¸é–¢åˆ†æ\n",
            "\n",
            "2. æ–½ç­–ææ¡ˆ\n",
            "- ç‰¹å®šã•ã‚ŒãŸå­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãå…·ä½“çš„ãªå£²ä¸Šå‘ä¸Šæ–½ç­–\n",
            "- å„æ–½ç­–ã®æœŸå¾…åŠ¹æœã¨å®Ÿè£…æ‰‹é †\n",
            "- ROIäºˆæ¸¬ã¨å„ªå…ˆé †ä½ä»˜ã‘\n",
            "\n",
            "å‡ºåŠ›å½¢å¼ï¼š\n",
            "```\n",
            "1. ãƒ‡ãƒ¼ã‚¿åˆ†æã‚µãƒãƒªãƒ¼\n",
            "   - ä¸»è¦ãªå­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
            "   - çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œè¨¼çµæœ\n",
            "   - é‡è¦ãªç›¸é–¢é–¢ä¿‚\n",
            "\n",
            "2. æ–½ç­–ææ¡ˆ\n",
            "   - æ–½ç­–å\n",
            "   - å®Ÿè£…æ™‚æœŸ\n",
            "   - æœŸå¾…åŠ¹æœ\n",
            "   - å®Ÿè£…æ‰‹é †\n",
            "   - å¿…è¦ãƒªã‚½ãƒ¼ã‚¹\n",
            "\n",
            "3. å„ªå…ˆé †ä½ä»˜ã‘ãƒãƒˆãƒªã‚¯ã‚¹\n",
            "   - å®Ÿè£…ã®å®¹æ˜“ã•\n",
            "   - æœŸå¾…åŠ¹æœ\n",
            "   - æ‰€è¦æœŸé–“\n",
            "```\n",
            "\n",
            "åˆ¶ç´„æ¡ä»¶ï¼š\n",
            "1. ã™ã¹ã¦ã®åˆ†æçµæœã¯95%ä¿¡é ¼åŒºé–“ã§ã®çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’ç¢ºä¿ã™ã‚‹ã“ã¨\n",
            "2. ææ¡ˆã™ã‚‹æ–½ç­–ã¯3ãƒ¶æœˆä»¥å†…ã«å®Ÿè£…å¯èƒ½ãªã‚‚ã®ã«é™å®šã™ã‚‹ã“ã¨\n",
            "3. æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã‚„ãƒªã‚½ãƒ¼ã‚¹ã§å®Ÿç¾å¯èƒ½ãªæ–½ç­–ã®ã¿ã‚’ææ¡ˆã™ã‚‹ã“ã¨\n",
            "4. æŠ•è³‡å›åæœŸé–“ã¯6ãƒ¶æœˆä»¥å†…ã‚’ç›®æ¨™ã¨ã™ã‚‹ã“ã¨\n",
            "\n",
            "ä¾‹ç¤ºï¼š\n",
            "æ–½ç­–ä¾‹ï¼š\n",
            "ã€Œå¤å­£ã‚¢ãƒ‘ãƒ¬ãƒ«æ—©æœŸå±•é–‹æ–½ç­–ã€\n",
            "- å®Ÿè£…æ™‚æœŸï¼š4æœˆä¸‹æ—¬\n",
            "- æœŸå¾…åŠ¹æœï¼šå‰å¹´æ¯”15%å£²ä¸Šå¢—\n",
            "- å…·ä½“ç­–ï¼š\n",
            "  1. 5æœˆä¸­æ—¬ã‹ã‚‰ã®ãƒ—ãƒ¬ã‚»ãƒ¼ãƒ«å®Ÿæ–½\n",
            "  2. ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’æ´»ç”¨ã—ãŸå…ˆè¡ŒPR\n",
            "  3. å¤å­£é™å®šå•†å“ã®æ—©æœŸå±•é–‹\n",
            "\n",
            "åˆ†æã®éš›ã¯ã€ä¸Šè¨˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã„ã¤ã¤ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå…·ä½“çš„ãªæ•°å€¤ã¨æ ¹æ‹ ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
          ]
        }
      ],
      "source": [
        "# å®Ÿéš›ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ä¾‹\n",
        "async def generate_prompt_example():\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®å®Ÿä¾‹\"\"\"\n",
        "    if not generator:\n",
        "        print(\"âš ï¸ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "        return None\n",
        "    \n",
        "    # ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ\n",
        "    task_type = \"data_analysis\"\n",
        "    requirements = \"ECã‚µã‚¤ãƒˆã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­£ç¯€æ€§ã‚’åˆ†æã—ã€å£²ä¸Šå‘ä¸Šæ–½ç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„\"\n",
        "    context = {\n",
        "        \"data_description\": \"æœˆåˆ¥å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆéå»2å¹´åˆ†ï¼‰\",\n",
        "        \"available_data\": \"å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šã€é¡§å®¢å±æ€§ãƒ‡ãƒ¼ã‚¿\",\n",
        "        \"analysis_objective\": \"å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®šã¨å£²ä¸Šå‘ä¸Š\"\n",
        "    }\n",
        "    constraints = \"çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼ã—ã€å®Ÿè£…å¯èƒ½ãªå…·ä½“çš„æ–½ç­–ã‚’ææ¡ˆã™ã‚‹ã“ã¨\"\n",
        "    examples = \"å¤å­£ã®ã‚¢ãƒ‘ãƒ¬ãƒ«å£²ä¸Šå¢—åŠ å‚¾å‘ã€å¹´æœ«å•†æˆ¦ã§ã®å®¶é›»å£²ä¸Šãƒ”ãƒ¼ã‚¯\"\n",
        "    \n",
        "    print(\"ğŸš€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...\")\n",
        "    print(\"\\n=== ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…å®¹ ===\")\n",
        "    print(f\"ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}\")\n",
        "    print(f\"è¦æ±‚: {requirements}\")\n",
        "    print(f\"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}\")\n",
        "    print(f\"åˆ¶ç´„: {constraints}\")\n",
        "    \n",
        "    try:\n",
        "        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Ÿè¡Œ\n",
        "        result = await generator.generate_prompt(\n",
        "            task_type=task_type,\n",
        "            requirements=requirements,\n",
        "            context=context,\n",
        "            constraints=constraints,\n",
        "            examples=examples\n",
        "        )\n",
        "        \n",
        "        print(\"\\n=== ç”Ÿæˆçµæœ ===\")\n",
        "        print(f\"âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”ŸæˆæˆåŠŸ\")\n",
        "        print(f\"é•·ã•: {len(result)}æ–‡å­—\")\n",
        "        \n",
        "        print(\"\\n=== ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ===\")\n",
        "        print(\"â”€\" * 50)\n",
        "        print(result)\n",
        "        print(\"â”€\" * 50)\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# å®Ÿè¡Œä¾‹\n",
        "if generator:\n",
        "    import asyncio\n",
        "    generated_prompt = asyncio.run(generate_prompt_example())\n",
        "else:\n",
        "    print(\"ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "kwp4du0mzf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™...\n",
            "è©•ä¾¡å¯¾è±¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é•·ã•: 273æ–‡å­—\n",
            "\n",
            "=== è©•ä¾¡çµæœ ===\n",
            "ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢:\n",
            "  âœ… clarity: 1.00/1.0\n",
            "  âœ… specificity: 0.80/1.0\n",
            "  âœ… completeness: 0.90/1.0\n",
            "  âœ… efficiency: 0.80/1.0\n",
            "  âš ï¸ reproducibility: 0.50/1.0\n",
            "\n",
            "ğŸ¯ ç·åˆã‚¹ã‚³ã‚¢: 0.82/1.0\n",
            "\n",
            "ğŸ’¡ æ”¹å–„ææ¡ˆ:\n",
            "  1. å‡ºåŠ›å½¢å¼ã®æ˜ç¢ºãªæŒ‡å®šã¨å…·ä½“ä¾‹ã‚’è¿½åŠ ã—ã¦ãã ã•ã„\n"
          ]
        }
      ],
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡ã®å®Ÿä¾‹\n",
        "def evaluate_prompt_example(prompt_content=None):\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹ä¾‹\"\"\"\n",
        "    if not evaluator:\n",
        "        print(\"âš ï¸ ã‚¨ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚¿ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "        return None\n",
        "    \n",
        "    # è©•ä¾¡å¯¾è±¡ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒ«ã¾ãŸã¯å‰ã®ã‚»ãƒ«ã§ç”Ÿæˆã—ãŸã‚‚ã®ï¼‰\n",
        "    if prompt_content is None:\n",
        "        prompt_content = \"\"\"\n",
        "ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚\n",
        "\n",
        "ã€åˆ†æå¯¾è±¡ã€‘\n",
        "ECã‚µã‚¤ãƒˆã®æœˆåˆ¥å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆéå»2å¹´åˆ†ï¼‰ã€å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Šã€é¡§å®¢å±æ€§ãƒ‡ãƒ¼ã‚¿\n",
        "\n",
        "ã€åˆ†æç›®çš„ã€‘\n",
        "å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®šã¨å£²ä¸Šå‘ä¸Šæ–½ç­–ã®ææ¡ˆ\n",
        "\n",
        "ã€åˆ†ææ‰‹æ³•ã€‘\n",
        "æ™‚ç³»åˆ—åˆ†æã€å­£ç¯€æ€§åˆ†è§£ã€ç›¸é–¢åˆ†æ\n",
        "\n",
        "ã€å‡ºåŠ›è¦ä»¶ã€‘\n",
        "1. å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯è¦–åŒ–ã¨è§£é‡ˆ\n",
        "2. çµ±è¨ˆçš„ã«æœ‰æ„ãªå‚¾å‘ã®ç‰¹å®š\n",
        "3. å…·ä½“çš„ãªå£²ä¸Šå‘ä¸Šæ–½ç­–ï¼ˆæœ€ä½3ã¤ï¼‰\n",
        "4. å„æ–½ç­–ã®ROIäºˆæ¸¬\n",
        "5. å®Ÿè£…å„ªå…ˆåº¦ã®ææ¡ˆ\n",
        "\n",
        "ã€åˆ¶ç´„æ¡ä»¶ã€‘\n",
        "- çµ±è¨ˆçš„æœ‰æ„æ€§ï¼ˆpå€¤<0.05ï¼‰ã‚’ç¢ºä¿ã™ã‚‹ã“ã¨\n",
        "- ãƒ“ã‚¸ãƒã‚¹å®Ÿè£…å¯èƒ½ãªæ–½ç­–ã®ã¿ææ¡ˆã™ã‚‹ã“ã¨\n",
        "- äºˆç®—åˆ¶ç´„ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨\n",
        "        \"\"\".strip()\n",
        "    \n",
        "    print(\"ğŸ¯ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
        "    print(f\"è©•ä¾¡å¯¾è±¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é•·ã•: {len(prompt_content)}æ–‡å­—\")\n",
        "    \n",
        "    try:\n",
        "        # å“è³ªè©•ä¾¡å®Ÿè¡Œ\n",
        "        scores = evaluator.evaluate(prompt_content)\n",
        "        \n",
        "        print(\"\\n=== è©•ä¾¡çµæœ ===\")\n",
        "        print(\"ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢:\")\n",
        "        for metric, score in scores.items():\n",
        "            if metric != 'overall':\n",
        "                status = \"âœ…\" if score >= 0.7 else \"âš ï¸\" if score >= 0.5 else \"âŒ\"\n",
        "                print(f\"  {status} {metric}: {score:.2f}/1.0\")\n",
        "        \n",
        "        print(f\"\\nğŸ¯ ç·åˆã‚¹ã‚³ã‚¢: {scores.get('overall', 0):.2f}/1.0\")\n",
        "        \n",
        "        # æ”¹å–„ææ¡ˆã‚’å–å¾—\n",
        "        suggestions = evaluator.get_improvement_suggestions(prompt_content, scores)\n",
        "        if suggestions:\n",
        "            print(\"\\nğŸ’¡ æ”¹å–„ææ¡ˆ:\")\n",
        "            for i, suggestion in enumerate(suggestions, 1):\n",
        "                print(f\"  {i}. {suggestion}\")\n",
        "        \n",
        "        return scores\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# å®Ÿè¡Œä¾‹\n",
        "if evaluator:\n",
        "    evaluation_result = evaluate_prompt_example()\n",
        "else:\n",
        "    print(\"ã‚¨ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "a4yi6wkpiq",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...\n",
            "\n",
            "ğŸ“ Step 1: åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:13:20,960 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: 943æ–‡å­—\n",
            "\n",
            "ğŸ“Š Step 2: åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªè©•ä¾¡\n",
            "åˆæœŸã‚¹ã‚³ã‚¢: 0.92/1.0\n",
            "\n",
            "ğŸš€ Step 3: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ãæ”¹å–„\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:13:42,280 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: 2219æ–‡å­—\n",
            "\n",
            "ğŸ“Š Step 4: æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªè©•ä¾¡\n",
            "æ”¹å–„å¾Œã‚¹ã‚³ã‚¢: 0.87/1.0\n",
            "\n",
            "=== æ”¹å–„çµæœã‚µãƒãƒªãƒ¼ ===\n",
            "åˆæœŸã‚¹ã‚³ã‚¢: 0.92/1.0\n",
            "æœ€çµ‚ã‚¹ã‚³ã‚¢: 0.87/1.0\n",
            "æ”¹å–„åº¦: -0.05ãƒã‚¤ãƒ³ãƒˆ\n",
            "âš ï¸ ã‚¹ã‚³ã‚¢ãŒä½ä¸‹ã—ã¾ã—ãŸï¼ˆå†æ”¹å–„ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼‰\n",
            "\n",
            "ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ¥ã®å¤‰åŒ–:\n",
            "  â– clarity: 0.90 â†’ 0.90 (+0.00)\n",
            "  â– specificity: 1.00 â†’ 1.00 (+0.00)\n",
            "  â– completeness: 1.00 â†’ 1.00 (+0.00)\n",
            "  ğŸ“‰ efficiency: 0.80 â†’ 0.50 (-0.30)\n",
            "  â– reproducibility: 0.80 â†’ 0.80 (+0.00)\n"
          ]
        }
      ],
      "source": [
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã®å®Ÿä¾‹\n",
        "async def improve_prompt_example():\n",
        "    \"\"\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„ã™ã‚‹ä¾‹\"\"\"\n",
        "    if not generator or not evaluator:\n",
        "        print(\"âš ï¸ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã¾ãŸã¯ã‚¨ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚¿ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "        return None\n",
        "    \n",
        "    print(\"ğŸ”„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
        "    \n",
        "    # Step 1: åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
        "    print(\"\\nğŸ“ Step 1: åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\")\n",
        "    \n",
        "    initial_prompt = await generator.generate_prompt(\n",
        "        task_type=\"text_processing\",\n",
        "        requirements=\"é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†æã—ã¦æ„Ÿæƒ…åˆ†æã¨è¦ç´„ã‚’è¡Œã„ãŸã„\",\n",
        "        context={\"data\": \"è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆ1000ä»¶ï¼‰\"},\n",
        "        constraints=\"å‡¦ç†æ™‚é–“ã¯5åˆ†ä»¥å†…\"\n",
        "    )\n",
        "    \n",
        "    if not initial_prompt:\n",
        "        print(\"âŒ åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
        "        return None\n",
        "        \n",
        "    print(f\"åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(initial_prompt)}æ–‡å­—\")\n",
        "    \n",
        "    # Step 2: å“è³ªè©•ä¾¡\n",
        "    print(\"\\nğŸ“Š Step 2: åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªè©•ä¾¡\")\n",
        "    initial_scores = evaluator.evaluate(initial_prompt)\n",
        "    \n",
        "    print(f\"åˆæœŸã‚¹ã‚³ã‚¢: {initial_scores.get('overall', 0):.2f}/1.0\")\n",
        "    \n",
        "    # Step 3: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„\n",
        "    print(\"\\nğŸš€ Step 3: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ãæ”¹å–„\")\n",
        "    \n",
        "    # æ”¹å–„ææ¡ˆã‚’å–å¾—\n",
        "    suggestions = evaluator.get_improvement_suggestions(initial_prompt, initial_scores)\n",
        "    feedback = \"ä»¥ä¸‹ã®ç‚¹ã‚’æ”¹å–„ã—ã¦ãã ã•ã„: \" + \", \".join(suggestions) if suggestions else \"ã‚ˆã‚Šå…·ä½“çš„ã§æ˜ç¢ºãªæŒ‡ç¤ºã‚’è¿½åŠ ã—ã¦ãã ã•ã„\"\n",
        "    \n",
        "    # æ”¹å–„å®Ÿè¡Œ\n",
        "    improved_prompt = generator.improve_prompt(initial_prompt, feedback)\n",
        "    \n",
        "    print(f\"æ”¹å–„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†: {len(improved_prompt)}æ–‡å­—\")\n",
        "    \n",
        "    # Step 4: æ”¹å–„å¾Œã®è©•ä¾¡\n",
        "    print(\"\\nğŸ“Š Step 4: æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªè©•ä¾¡\")\n",
        "    final_scores = evaluator.evaluate(improved_prompt)\n",
        "    \n",
        "    print(f\"æ”¹å–„å¾Œã‚¹ã‚³ã‚¢: {final_scores.get('overall', 0):.2f}/1.0\")\n",
        "    \n",
        "    # çµæœæ¯”è¼ƒ\n",
        "    print(\"\\n=== æ”¹å–„çµæœã‚µãƒãƒªãƒ¼ ===\")\n",
        "    initial_overall = initial_scores.get('overall', 0)\n",
        "    final_overall = final_scores.get('overall', 0)\n",
        "    improvement = final_overall - initial_overall\n",
        "    \n",
        "    print(f\"åˆæœŸã‚¹ã‚³ã‚¢: {initial_overall:.2f}/1.0\")\n",
        "    print(f\"æœ€çµ‚ã‚¹ã‚³ã‚¢: {final_overall:.2f}/1.0\")\n",
        "    print(f\"æ”¹å–„åº¦: {improvement:+.2f}ãƒã‚¤ãƒ³ãƒˆ\")\n",
        "    \n",
        "    if improvement > 0:\n",
        "        print(\"âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªãŒå‘ä¸Šã—ã¾ã—ãŸï¼\")\n",
        "    elif improvement == 0:\n",
        "        print(\"â– ã‚¹ã‚³ã‚¢ã«å¤‰åŒ–ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
        "    else:\n",
        "        print(\"âš ï¸ ã‚¹ã‚³ã‚¢ãŒä½ä¸‹ã—ã¾ã—ãŸï¼ˆå†æ”¹å–„ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼‰\")\n",
        "    \n",
        "    # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¤‰åŒ–ã‚’è¡¨ç¤º\n",
        "    print(\"\\nğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ¥ã®å¤‰åŒ–:\")\n",
        "    for metric in ['clarity', 'specificity', 'completeness', 'efficiency', 'reproducibility']:\n",
        "        initial_val = initial_scores.get(metric, 0)\n",
        "        final_val = final_scores.get(metric, 0)\n",
        "        change = final_val - initial_val\n",
        "        status = \"ğŸ“ˆ\" if change > 0 else \"ğŸ“‰\" if change < 0 else \"â–\"\n",
        "        print(f\"  {status} {metric}: {initial_val:.2f} â†’ {final_val:.2f} ({change:+.2f})\")\n",
        "    \n",
        "    return {\n",
        "        'initial_prompt': initial_prompt,\n",
        "        'improved_prompt': improved_prompt,\n",
        "        'initial_scores': initial_scores,\n",
        "        'final_scores': final_scores\n",
        "    }\n",
        "\n",
        "# å®Ÿè¡Œä¾‹\n",
        "if generator and evaluator:\n",
        "    import asyncio\n",
        "    improvement_result = asyncio.run(improve_prompt_example())\n",
        "else:\n",
        "    print(\"ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨ã‚¨ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "vrdizkw96v",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆã‚’é–‹å§‹...\n",
            "\n",
            "ğŸ“ ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:13:53,088 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… å®Œäº†: 680æ–‡å­—\n",
            "\n",
            "ğŸ“ ç”»åƒèªè­˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:14:06,209 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… å®Œäº†: 1291æ–‡å­—\n",
            "\n",
            "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:14:17,928 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… å®Œäº†: 942æ–‡å­—\n",
            "\n",
            "ğŸ“ è¦ä»¶åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:14:30,228 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… å®Œäº†: 737æ–‡å­—\n",
            "\n",
            "ğŸ“ APIãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:14:43,793 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… å®Œäº†: 1009æ–‡å­—\n",
            "\n",
            "ğŸ“ æ±ç”¨PoCãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 15:14:54,733 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… å®Œäº†: 635æ–‡å­—\n",
            "\n",
            "=== ç”Ÿæˆçµæœã‚µãƒãƒªãƒ¼ ===\n",
            "âœ… ãƒ‡ãƒ¼ã‚¿åˆ†æ: 680æ–‡å­—\n",
            "âœ… ç”»åƒèªè­˜: 1291æ–‡å­—\n",
            "âœ… ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†: 942æ–‡å­—\n",
            "âœ… è¦ä»¶åˆ†æ: 737æ–‡å­—\n",
            "âœ… APIãƒ†ã‚¹ãƒˆ: 1009æ–‡å­—\n",
            "âœ… æ±ç”¨PoC: 635æ–‡å­—\n",
            "\n",
            "æˆåŠŸç‡: 6/6 (100%)\n",
            "\n",
            "=== ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤ºï¼ˆãƒ‡ãƒ¼ã‚¿åˆ†æï¼‰ ===\n",
            "ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ææ¡ˆã•ã›ã¦ã„ãŸã ãã¾ã™ï¼š\n",
            "\n",
            "```\n",
            "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã¨ã—ã¦ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã¨å®Ÿç”¨çš„ãªæ´å¯Ÿã®æä¾›ã‚’æ‹…å½“ã—ã¾ã™ã€‚\n",
            "\n",
            "ã‚¿ã‚¹ã‚¯ï¼š\n",
            "æä¾›ã•ã‚Œã‚‹3å¹´åˆ†ã®æœˆæ¬¡å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€åŒ…æ‹¬çš„ãªæ™‚ç³»åˆ—åˆ†æã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚\n",
            "\n",
            "å…·ä½“çš„ã«å®Ÿæ–½ã—ã¦ã„ãŸã ããŸã„åˆ†æï¼š\n",
            "1. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ\n",
            "   - é•·æœŸçš„ãªæˆé•·å‚¾å‘ã®ç‰¹å®š\n",
            "   - å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º\n",
            "2. å¤‰å‹•è¦å› ã®åˆ†è§£\n",
            "   - ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†\n",
            "   - å­£ç¯€æˆåˆ†\n",
            "   - ãƒ©ãƒ³ãƒ€ãƒ æˆåˆ†\n",
            "3. ç•°å¸¸å€¤ã®æ¤œå‡ºã¨è§£é‡ˆ\n",
            "\n",
            "æœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼ï¼š\n",
            "1. åˆ†æã‚µãƒãƒªãƒ¼ï¼ˆ200-300æ–‡å­—ï¼‰\n",
            "2. ä¸»è¦ãªç™ºè¦‹äº‹é …ï¼ˆç®‡æ¡æ›¸ã3-5é …ç›®ï¼‰\n",
            "3. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå„ªå…ˆé †ä½ä»˜ã3é …ç›®ï¼‰\n",
            "4. å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ï¼ˆä»¥ä¸‹ã‚’å«ã‚€ã“ã¨ï¼‰\n",
            "   - ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³\n",
            "   - å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
            "   - ç•°å¸¸å€¤ã®ãƒãƒ¼ã‚­ãƒ³ã‚°\n",
            "\n",
            "åˆ¶ç´„æ¡ä»¶ï¼š\n",
            "- çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’å¿…ãšç¢ºèªã™ã‚‹ã“ã¨\n",
            "- æ¥­ç•Œæ¨™æº–ã®åˆ†ææ‰‹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨\n",
            "- ä»®èª¬ã¯å®šé‡çš„ãªãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã“ã¨\n",
            "\n",
            "åˆ†æä¾‹ï¼š\n",
            "ã€Œ2021å¹´1æœˆã‹ã‚‰2023å¹´12æœˆã¾ã§ã®æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ãŸçµæœã€å¹´å¹³å‡æˆé•·ç‡ã¯8.2%ã§ã€\n",
            "ç‰¹ã«...\n"
          ]
        }
      ],
      "source": [
        "# å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ\n",
        "async def generate_all_types_example():\n",
        "    \"\"\"å…¨ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ\"\"\"\n",
        "    if not generator:\n",
        "        print(\"âš ï¸ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "        return None\n",
        "    \n",
        "    print(\"ğŸ¯ å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆã‚’é–‹å§‹...\")\n",
        "    \n",
        "    # å„ã‚¿ã‚¤ãƒ—ã®è¨­å®š\n",
        "    prompt_configs = [\n",
        "        {\n",
        "            'type': 'data_analysis',\n",
        "            'name': 'ãƒ‡ãƒ¼ã‚¿åˆ†æ',\n",
        "            'requirements': 'å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã®æ™‚ç³»åˆ—åˆ†æã‚’è¡Œã„ãŸã„',\n",
        "            'context': {'data': 'æœˆæ¬¡å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆ3å¹´åˆ†ï¼‰'}\n",
        "        },\n",
        "        {\n",
        "            'type': 'image_recognition',\n",
        "            'name': 'ç”»åƒèªè­˜',\n",
        "            'requirements': 'è£½å“ç”»åƒã‹ã‚‰ä¸è‰¯å“ã‚’æ¤œå‡ºã—ãŸã„',\n",
        "            'context': {'data': 'å·¥å ´ã®å“è³ªæ¤œæŸ»ç”»åƒãƒ‡ãƒ¼ã‚¿'}\n",
        "        },\n",
        "        {\n",
        "            'type': 'text_processing',\n",
        "            'name': 'ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†',\n",
        "            'requirements': 'SNSã®æŠ•ç¨¿ã‹ã‚‰æ„Ÿæƒ…åˆ†æã‚’è¡Œã„ãŸã„',\n",
        "            'context': {'data': 'Twitter/Xã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿'}\n",
        "        },\n",
        "        {\n",
        "            'type': 'requirements_analysis',\n",
        "            'name': 'è¦ä»¶åˆ†æ',\n",
        "            'requirements': 'æ–°è¦Webã‚¢ãƒ—ãƒªã®è¦ä»¶å®šç¾©ã‚’è¡Œã„ãŸã„',\n",
        "            'context': {'project': 'BtoB SaaSãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ'}\n",
        "        },\n",
        "        {\n",
        "            'type': 'api_testing',\n",
        "            'name': 'APIãƒ†ã‚¹ãƒˆ',\n",
        "            'requirements': 'REST APIã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ä½œæˆã—ãŸã„',\n",
        "            'context': {'api': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†API'}\n",
        "        },\n",
        "        {\n",
        "            'type': 'general_poc',\n",
        "            'name': 'æ±ç”¨PoC',\n",
        "            'requirements': 'AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®PoCã‚’ä½œæˆã—ãŸã„',\n",
        "            'context': {'purpose': 'ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆå‘ã‘'}\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for config in prompt_configs:\n",
        "        print(f\"\\nğŸ“ {config['name']}ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­...\")\n",
        "        \n",
        "        try:\n",
        "            result = await generator.generate_prompt(\n",
        "                task_type=config['type'],\n",
        "                requirements=config['requirements'],\n",
        "                context=config['context']\n",
        "            )\n",
        "            \n",
        "            results[config['type']] = {\n",
        "                'name': config['name'],\n",
        "                'prompt': result,\n",
        "                'length': len(result)\n",
        "            }\n",
        "            print(f\"  âœ… å®Œäº†: {len(result)}æ–‡å­—\")\n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "            results[config['type']] = None\n",
        "    \n",
        "    # çµæœè¡¨ç¤º\n",
        "    print(\"\\n=== ç”Ÿæˆçµæœã‚µãƒãƒªãƒ¼ ===\")\n",
        "    success_count = 0\n",
        "    for type_key, result in results.items():\n",
        "        if result:\n",
        "            print(f\"âœ… {result['name']}: {result['length']}æ–‡å­—\")\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\"âŒ {type_key}: ç”Ÿæˆå¤±æ•—\")\n",
        "    \n",
        "    print(f\"\\næˆåŠŸç‡: {success_count}/{len(prompt_configs)} ({success_count/len(prompt_configs)*100:.0f}%)\")\n",
        "    \n",
        "    # æœ€åˆã®æˆåŠŸã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€éƒ¨ã‚’è¡¨ç¤º\n",
        "    for type_key, result in results.items():\n",
        "        if result:\n",
        "            print(\"\\n=== ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤ºï¼ˆ\" + result['name'] + \"ï¼‰ ===\")\n",
        "            print(result['prompt'][:500] + \"...\" if len(result['prompt']) > 500 else result['prompt'])\n",
        "            break\n",
        "    \n",
        "    return results\n",
        "\n",
        "# å®Ÿè¡Œä¾‹\n",
        "if generator:\n",
        "    import asyncio\n",
        "    all_prompts = asyncio.run(generate_all_types_example())\n",
        "else:\n",
        "    print(\"ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}