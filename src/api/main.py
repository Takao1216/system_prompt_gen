"""
FastAPI ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®Web APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
"""

import os
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
from datetime import datetime
from dotenv import load_dotenv
import anthropic

from ..prompt_engine.generator import PromptGenerator, PromptRequest, PromptType, GeneratedPrompt
from ..prompt_engine.evaluator import PromptEvaluator
from ..langgraph_workflows.prompt_workflow import PromptImprovementWorkflow, WorkflowConfig

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=getattr(logging, os.getenv('LOG_LEVEL', 'INFO')),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
anthropic_client = None
prompt_generator = None
prompt_evaluator = None
workflow = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†"""
    global anthropic_client, prompt_generator, prompt_evaluator, workflow
    
    # èµ·å‹•æ™‚ã®åˆæœŸåŒ–
    logger.info("Initializing application...")
    
    api_key = os.getenv('ANTHROPIC_API_KEY')
    if not api_key:
        logger.error("ANTHROPIC_API_KEY not found in environment variables")
        raise ValueError("ANTHROPIC_API_KEY is required")
    
    anthropic_client = anthropic.AsyncAnthropic(api_key=api_key)
    
    # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
    model_name = os.getenv('DEFAULT_MODEL', 'claude-3-sonnet-20240229')
    prompt_generator = PromptGenerator(anthropic_client, model_name)
    prompt_evaluator = PromptEvaluator(anthropic_client, model_name)
    
    workflow_config = WorkflowConfig(
        max_iterations=3,
        quality_threshold=8.0,
        temperature=float(os.getenv('TEMPERATURE', '0.7')),
        max_tokens=int(os.getenv('MAX_TOKENS', '4000')),
        model_name=model_name
    )
    workflow = PromptImprovementWorkflow(anthropic_client, workflow_config)
    
    logger.info("Application initialized successfully")
    
    yield
    
    # ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    logger.info("Shutting down application...")


# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
app = FastAPI(
    title="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  API",
    description="AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘PoCé–‹ç™ºæ”¯æ´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ",
    version="1.0.0",
    lifespan=lifespan
)

# CORSè¨­å®š
cors_origins = os.getenv('CORS_ORIGINS', 'http://localhost:8000').split(',')
app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«å®šç¾©
class PromptGenerationRequest(BaseModel):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    prompt_type: str = "general_poc"
    user_requirements: str
    context: str = ""
    domain: str = ""
    output_format: str = "structured"
    constraints: List[str] = []
    examples: List[str] = []


class PromptGenerationResponse(BaseModel):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    success: bool
    prompt: str
    metadata: Dict[str, Any]
    quality_score: float = 0.0
    suggestions: List[str] = []
    created_at: str
    error: Optional[str] = None


class PromptEvaluationRequest(BaseModel):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    prompt_content: str
    original_request: str = ""
    context: str = ""


class PromptEvaluationResponse(BaseModel):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    success: bool
    quality_scores: Dict[str, float]
    feedback: str
    suggestions: List[str]
    strengths: List[str]
    weaknesses: List[str]
    evaluation_timestamp: str
    error: Optional[str] = None


class WorkflowRequest(BaseModel):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    user_request: str
    context: str = ""
    prompt_type: str = "general_poc"
    domain: str = ""


class WorkflowResponse(BaseModel):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    success: bool
    workflow_id: str
    final_prompt: str
    quality_scores: Dict[str, float]
    iteration_count: int
    is_satisfactory: bool
    processing_logs: List[str]
    error: Optional[str] = None


# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/", response_class=HTMLResponse)
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ - APIæ¦‚è¦ãƒšãƒ¼ã‚¸"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  API</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; }
            h1 { color: #333; }
            .endpoint { background: #f5f5f5; padding: 10px; margin: 10px 0; border-radius: 5px; }
            .method { font-weight: bold; color: #007bff; }
            .path { color: #28a745; }
        </style>
    </head>
    <body>
        <h1>ğŸš€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  API</h1>
        <p>AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘PoCé–‹ç™ºæ”¯æ´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®APIã§ã™ã€‚</p>
        
        <h2>åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ</h2>
        
        <div class="endpoint">
            <span class="method">GET</span> <span class="path">/health</span>
            <p>ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ</p>
        </div>
        
        <div class="endpoint">
            <span class="method">POST</span> <span class="path">/api/v1/generate</span>
            <p>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ</p>
        </div>
        
        <div class="endpoint">
            <span class="method">POST</span> <span class="path">/api/v1/evaluate</span>
            <p>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡</p>
        </div>
        
        <div class="endpoint">
            <span class="method">POST</span> <span class="path">/api/v1/workflow</span>
            <p>è‡ªå‹•æ”¹å–„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ</p>
        </div>
        
        <div class="endpoint">
            <span class="method">GET</span> <span class="path">/api/v1/prompt-types</span>
            <p>åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ä¸€è¦§</p>
        </div>
        
        <div class="endpoint">
            <span class="method">GET</span> <span class="path">/api/v1/statistics</span>
            <p>ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆæƒ…å ±</p>
        </div>
        
        <h2>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</h2>
        <ul>
            <li><a href="/docs">Swagger UI (å¯¾è©±çš„APIæ–‡æ›¸)</a></li>
            <li><a href="/redoc">ReDoc (APIä»•æ§˜æ›¸)</a></li>
        </ul>
    </body>
    </html>
    """
    return HTMLResponse(content=html_content)


@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "anthropic_client": anthropic_client is not None,
            "prompt_generator": prompt_generator is not None,
            "prompt_evaluator": prompt_evaluator is not None,
            "workflow": workflow is not None
        }
    }


@app.post("/api/v1/generate", response_model=PromptGenerationResponse)
async def generate_prompt(request: PromptGenerationRequest):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        # PromptRequestã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        prompt_request = PromptRequest(
            prompt_type=PromptType(request.prompt_type),
            user_requirements=request.user_requirements,
            context=request.context,
            domain=request.domain,
            output_format=request.output_format,
            constraints=request.constraints,
            examples=request.examples
        )
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        result = await prompt_generator.generate_prompt(prompt_request)
        
        return PromptGenerationResponse(
            success=True,
            prompt=result.content,
            metadata=result.metadata,
            quality_score=result.quality_score,
            suggestions=result.suggestions,
            created_at=result.created_at
        )
        
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return PromptGenerationResponse(
            success=False,
            prompt="",
            metadata={},
            created_at=datetime.now().isoformat(),
            error=str(e)
        )


@app.post("/api/v1/evaluate", response_model=PromptEvaluationResponse)
async def evaluate_prompt(request: PromptEvaluationRequest):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡å®Ÿè¡Œ
        result = await prompt_evaluator.evaluate_prompt(
            prompt_content=request.prompt_content,
            original_request=request.original_request,
            context=request.context
        )
        
        return PromptEvaluationResponse(
            success=True,
            quality_scores=result.metrics.to_dict(),
            feedback=result.feedback,
            suggestions=result.suggestions,
            strengths=result.strengths,
            weaknesses=result.weaknesses,
            evaluation_timestamp=result.evaluation_timestamp
        )
        
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return PromptEvaluationResponse(
            success=False,
            quality_scores={},
            feedback="",
            suggestions=[],
            strengths=[],
            weaknesses=[],
            evaluation_timestamp=datetime.now().isoformat(),
            error=str(e)
        )


@app.post("/api/v1/workflow", response_model=WorkflowResponse)
async def run_workflow(request: WorkflowRequest, background_tasks: BackgroundTasks):
    """è‡ªå‹•æ”¹å–„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
        result = await workflow.run_workflow(
            user_request=request.user_request,
            context=request.context,
            prompt_type=request.prompt_type,
            domain=request.domain
        )
        
        return WorkflowResponse(
            success=True,
            workflow_id=result["workflow_id"],
            final_prompt=result["current_prompt"],
            quality_scores=result["quality_scores"],
            iteration_count=result["iteration_count"],
            is_satisfactory=result["is_satisfactory"],
            processing_logs=result["processing_logs"]
        )
        
    except Exception as e:
        logger.error(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        return WorkflowResponse(
            success=False,
            workflow_id="",
            final_prompt="",
            quality_scores={},
            iteration_count=0,
            is_satisfactory=False,
            processing_logs=[],
            error=str(e)
        )


@app.get("/api/v1/prompt-types")
async def get_prompt_types():
    """åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ä¸€è¦§"""
    return {
        "prompt_types": [
            {
                "value": pt.value,
                "name": pt.name,
                "description": {
                    "data_analysis": "ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»å¯è¦–åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                    "image_recognition": "ç”»åƒèªè­˜ãƒ»åˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                    "text_processing": "ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ»NLPãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                    "requirements_analysis": "è¦ä»¶å®šç¾©æ”¯æ´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                    "api_testing": "APIãƒ†ã‚¹ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                    "general_poc": "æ±ç”¨PoCç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
                }.get(pt.value, "")
            }
            for pt in PromptType
        ]
    }


@app.get("/api/v1/statistics")
async def get_statistics():
    """ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆæƒ…å ±"""
    try:
        generator_stats = prompt_generator.get_generation_stats() if prompt_generator else {}
        evaluator_stats = prompt_evaluator.get_evaluation_statistics() if prompt_evaluator else {}
        workflow_stats = workflow.get_workflow_statistics() if workflow else {}
        
        return {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "statistics": {
                "generation": generator_stats,
                "evaluation": evaluator_stats,
                "workflow": workflow_stats
            }
        }
        
    except Exception as e:
        logger.error(f"çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "statistics": {}
        }


if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv('APP_HOST', 'localhost')
    port = int(os.getenv('APP_PORT', '8000'))
    
    uvicorn.run(
        "src.api.main:app",
        host=host,
        port=port,
        reload=os.getenv('DEBUG_MODE', 'true').lower() == 'true'
    )